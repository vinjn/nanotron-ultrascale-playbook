# Qwen3的“混合推理”是如何实现的

**Author:** GEN

**Date:** 2025-05-04

**Link:** https://zhuanlan.zhihu.com/p/1902557935348978792

阿里巴巴通义千问团队最新发布的 [Qwen3](https://zhida.zhihu.com/search?content_id=257322990&content_type=Article&match_order=1&q=Qwen3&zhida_source=entity) 大语言模型系列带来了许多令人兴奋的特性，其中最引人注目的创新之一无疑是其“[混合推理](https://zhida.zhihu.com/search?content_id=257322990&content_type=Article&match_order=1&q=%E6%B7%B7%E5%90%88%E6%8E%A8%E7%90%86&zhida_source=entity)”。这个功能赋予了开发者前所未有的灵活性，可以根据具体需求在模型的“思考”与“非思考”状态间切换。

这听起来很酷，但它到底是什么？又是如何工作的呢？让我们一起深入了解一下。

![](https://pica.zhimg.com/v2-d8f2a3c186f9a3d0a2bca139cf81d728_1440w.jpg)

## 什么是混合推理？

简单来说，Qwen3 可以在两种不同的模式下运行：

[思考模式](https://zhida.zhihu.com/search?content_id=257322990&content_type=Article&match_order=1&q=%E6%80%9D%E8%80%83%E6%A8%A1%E5%BC%8F&zhida_source=entity) (Thinking Mode): 在这种模式下，模型会模拟人类解决复杂问题时的思考过程。它会进行更深入的分析、逐步推理（step-by-step reasoning），并将这个思考过程的“痕迹”或中间步骤纳入考量（甚至可能在输出中体现，具体取决于配置）。这对于需要严谨逻辑、复杂推理或创造性解决方案的任务（如数学题、代码生成、深度分析报告）非常有益。

[非思考模式](https://zhida.zhihu.com/search?content_id=257322990&content_type=Article&match_order=1&q=%E9%9D%9E%E6%80%9D%E8%80%83%E6%A8%A1%E5%BC%8F&zhida_source=entity) (Non-Thinking Mode): 当模型处于此模式时，它会跳过显式的、逐步的内部“思考”环节，旨在提供更快速、更直接的响应。这非常适合那些答案相对直接、不需要冗长推理过程的场景，例如简单的问答、快速信息检索或常规对话。

混合推理的核心优势在于灵活性和效率：

1\. 按需优化：开发者可以根据任务的复杂性选择最合适的模式。复杂任务用“思考模式”保证质量，简单任务用“非思考模式”提升速度、降低延迟和计算成本。

2\. 成本效益：“思考”通常意味着更多的计算资源消耗。在不需要深度思考时切换到“非思考”模式，可以有效节省资源。

3.用户体验： 对于需要快速反馈的应用场景，“非思考模式”可以提供更流畅的交互体验。

## 如何跳过思考？

那么，Qwen3 是如何知道何时“思考”，何时“跳过思考”的呢？关键在于输入给模型的提示模板结构。

我们来看一段代码：

```python3
prompt = "介绍什么是LLM "
messages = [
 {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
 messages,
 tokenize=False,
 add_generation_prompt=True,
 enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.
)
print(text)
```

tokenizer.apply\_chat\_template 这个函数负责将对话历史（messages）转换成模型能够理解的特定格式字符串。其中一个重要的参数就是 enable\_thinking。

让我们看看这个参数如何影响最终输入给模型的文本：

```text
# --- 情况一：启用思考模式 ---
text = tokenizer.apply_chat_template(
 messages,
 tokenize=False,
 add_generation_prompt=True,
 enable_thinking=True # 明确启用思考
)
print(text)
```

当 enable\_thinking=True 时，生成的模板如下：

```text
<|im_start|>user
介绍什么是LLM <|im_end|>
<|im_start|>assistant
```

这个模板跟Qwen2.5一致，模型将会根据模板中的内容，给出思考和回复的内容。这也说明，Qwen3本身就是一个推理模型，能够自动进行推理。

再来看一下enable\_thinking=False时：

```text
# --- 情况二：不启用思考模式 ---
text = tokenizer.apply_chat_template(
 messages,
 tokenize=False,
 add_generation_prompt=True,
 enable_thinking=False # 不启用思考
)
print(text)
```

当 enable\_thinking=False 时，生成的模板如下：

```text
<|im_start|>user
介绍什么是LLM/no_think<|im_end|>
<|im_start|>assistant
<think>
 
</think>
从生成的模板中可以看出，在不启用思考时，实际上就是生成一个空白的思考内容，让模型误以为思考过程已经完成，从而直接生成输出内容。
```

## 软切换

Qwen3还提供了一个高级用法：

允许用户在 enable\_thinking=True 时动态控制模型的行为。具体来说，您可以在用户提示或系统消息中添加 “/think“ 和 “/no\_think“ 来逐轮切换模型的思考模式。在多轮对话中，模型会遵循最近的指令。

在开启深度的前提下，当用户的输入中带有“/no\_think”时：

![](https://pica.zhimg.com/v2-660882515ad11a13940f03c7f47b6464_1440w.jpg)

当用户的输入中带有“/think”时：

![](https://pic4.zhimg.com/v2-005e268edd7066ca13e76adfaa700f6f_1440w.jpg)

我们也可以展示一个本地推理的例子：

```text
输入：
<|im_start|>user
介绍什么是LLM/no_think<|im_end|>
<|im_start|>assistant
输出：
 <think>
 
</think>
content: LLM（Large Language Model，大语言模型）是人工智能领域中的一种重要技术，属于**自然语言处理（NLP）**的高级应用。它是一种**深度学习模型**，能够理解、生成和交互人类语言，具有强大的语言理解、生成、推理和对话能力。
 
---
 
## 一、LLM 的基本概念
 
### 1. **LLM 的定义**
LLM 是一种**基于大规模文本数据训练的机器学习模型**，能够理解并生成自然语言，具有**语言理解、语言生成、语义推理、对话交互**等能力。
 
### 2. **LLM 的特点**
- **大规模**：通常基于数亿甚至数十亿个词的文本数据训练。
- **通用性**：能处理多种语言（如中文、英文、日文等）。
- **可微分**：通过反向传播等技术优化模型参数。
- **可解释性**：可以解释模型的决策过程（尽管复杂）。
- **可微分**：可以通过梯度下降等方法进行优化。
......
```

若“/no\_think”与“/think”同时出现时，则以最后出现的为准。

我们可以探索一下“/no\_think”与“/think”是否会对模板产生影响：

```text
prompt = "介绍什么是LLM/no_think"
messages = [
 {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
 messages,
 tokenize=False,
 add_generation_prompt=True,
 enable_thinking=True 
)
print(text)
```

输出：

```text
<|im_start|>user
介绍什么是LLM/no_think<|im_end|>
<|im_start|>assistant
```

这说明“/no\_think”与“/think”并不会对模板产生影响。而是通过模型本身的能力来理解是否应该产生思考。

这是因为Qwen3在训练时单独对“/no\_think”与“/ think”进行了处理。具体的实现思路还需要等Qwen3的论文公布后才可得知。

## 总结：

1\. Qwen3通过预定义空白思考的方式，强制模型跳过思考过程。

2\. Qwen3对“/no\_think”与“/think”进行了单独的训练，使其不输出思考过程，实现软切换。但这种方式是依靠的是LLM本身的预测能力实现的，并不是完全可靠。