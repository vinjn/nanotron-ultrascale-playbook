# pytorch 源码分析 (12) sort (2)

**Author:** 阿嚏

**Date:** 2025-07-16

**Link:** https://zhuanlan.zhihu.com/p/1928376720311948431

上一篇文章我们分析了一下，当数据量较小时pytorch使用自己原生的双调排序[pytorch 源码分析 （11）sort (1)](https://zhuanlan.zhihu.com/p/1926998363087307228)

但这种场景并不算多，当排序大量数据的时候，pytorch更多的是调用[cub库](https://zhida.zhihu.com/search?content_id=260348387&content_type=Article&match_order=1&q=cub%E5%BA%93&zhida_source=entity)中的[基数排序](https://zhida.zhihu.com/search?content_id=260348387&content_type=Article&match_order=1&q=%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F&zhida_source=entity)。

cub库是nvidia的一个库，平时装[cuda toolkit](https://zhida.zhihu.com/search?content_id=260348387&content_type=Article&match_order=1&q=cuda+toolkit&zhida_source=entity)时候顺便装上去了，其位置在/usr/local/cuda/targets/x86\_64-linux/include/cub中，是头文件库，今天我们来分析一下其基数排序的实现。

先看一下pytorch部分代码，对于tensor的排序，往往是将values和indices一起排序的，所以叫做sort pairs，也成为kv排序，其中k是values，v是indices。其实现代码位于sort\_cuda\_kernel，sort\_cuda\_kernel判断一下，如果数值比较少，适合should\_use\_small\_sort，就用前文介绍过的双调排序等排序算法，其次就是最终的values和indices 如果strides对不上，就重新创建一个，核心工作还是调用launch\_stable\_sort\_kernel来完成。其代码比较简单，这里就不放了。

launch\_stable\_sort\_kernel取名有点不规范，本质上排序问题还是(batch,dim)问题，nsort对应dim, nbatch对应的不是batch，而是batch\*dim，也就是总数量，不考虑nbatch超过intmax的情况，nbatch = batch\* dim

remaining就是剩下的元素数量，nsegments对应的是batch，在不同的数据场景下，选取不同的排序算法。

```text
void launch_stable_sort_kernel(
    const TensorBase& self,
    int64_t dim,
    bool descending,
    const TensorBase& values,
    const TensorBase& indices) {
  const auto numel = self.numel();
  if (numel == 0) {
    return;
  }

  int64_t numel_or_intmax =
      std::min(numel, static_cast<int64_t>(std::numeric_limits<int>::max()));
  int64_t nsort = self.size(dim);
  int64_t nbatch = (numel_or_intmax / nsort) * nsort;
  TORCH_CHECK(nbatch > 0, "Cannot sort dimension of length ", nsort);
  int64_t* indices_ptr = indices.mutable_data_ptr<int64_t>();

  AT_DISPATCH_ALL_TYPES_AND3(
      kBool, kHalf, kBFloat16, self.scalar_type(), "sort", [&] {
        const scalar_t* self_ptr = self.const_data_ptr<scalar_t>();
        scalar_t* values_ptr = values.mutable_data_ptr<scalar_t>();
        int64_t remaining = numel;
        while (remaining > 0) {
          int64_t n = std::min(remaining, nbatch);
          int64_t nsegments = n / nsort;

          if (nsegments == 1 ||
              nsort >= 1000000) { // rough heuristics where even a single
                                  // sort occupies GPU
            segmented_sort_large_segments(
                nsegments,
                nsort,
                n,
                descending,
                self_ptr,
                values_ptr,
                indices_ptr);
          } else if (nsegments < 128) {
            segmented_sort_pairs_by_full_sort(
                nsegments,
                nsort,
                n,
                descending,
                self_ptr,
                values_ptr,
                indices_ptr);
          } else {
            segmented_sort_pairs(
                nsegments,
                nsort,
                n,
                descending,
                self_ptr,
                values_ptr,
                indices_ptr);
          }

          remaining -= n;
          self_ptr += n;
          values_ptr += n;
          indices_ptr += n;
        }
      });
}
```

这里我们先看比较简单的 segmented\_sort\_pairs，对于(batch,dim)问题，其需要满足batch >=128, dim < 1000000

其参数，nsegments对应batch, nsort对应dim，n对应元素总数量batch\*dim descending true是降序，false是升序，还有三个指针，分别是数据指针和values指针以及indices指针。

```text
template <typename scalar_t>
void segmented_sort_pairs(
    int64_t nsegments,
    int64_t nsort,
    int64_t n,
    bool descending,
    const scalar_t* self_ptr,
    scalar_t* values_ptr,
    int64_t* indices_ptr) {
  const auto numel = nsort * nsegments;
  auto cuda_allocator = at::cuda::getCUDADeviceAllocator();
  auto reverse_indices = cuda_allocator->allocate(numel * sizeof(int64_t));
  int64_t* reverse_indices_ptr = static_cast<int64_t*>(reverse_indices.get());

  using namespace at::cuda::detail;
  dim3 block = CUDA_NUM_THREADS;
  dim3 grid = GET_BLOCKS(numel);
  auto stream = c10::cuda::getCurrentCUDAStream();
  at::cuda::detail::IntDivider<uint32_t> nsort_divider(nsort);
  fill_reverse_indices_kernel<<<grid, block, 0, stream>>>(
      reverse_indices_ptr, numel, nsort_divider);

  at::cuda::cub::segmented_sort_pairs(
      self_ptr,
      values_ptr,
      reverse_indices_ptr,
      indices_ptr,
      n,
      nsegments,
      offset_t{(int)nsort, 0},
      offset_t{(int)nsort, 1},
      descending);
}
```

线程是固定死的1024 CUDA\_NUM\_THREADS，一般1024个线程比较适合32\*32进行block reduce, grid的选取就是全部数据的数量除1024，这时候总共的线程数就是数据数量了。

```text
// Use 1024 threads per block, which requires cuda sm_2x or above
constexpr int CUDA_NUM_THREADS = 1024;

// CUDA: number of blocks for threads.
inline int GET_BLOCKS(const int64_t N, const int64_t max_threads_per_block=CUDA_NUM_THREADS) {
  TORCH_INTERNAL_ASSERT(N > 0, "CUDA kernel launch blocks must be positive, but got N=", N);
  constexpr int64_t max_int = std::numeric_limits<int>::max();

  // Round up division for positive number that cannot cause integer overflow
  auto block_num = (N - 1) / max_threads_per_block + 1;
  TORCH_INTERNAL_ASSERT(block_num <= max_int, "Can't schedule too many blocks on CUDA device");

  return static_cast<int>(block_num);
}
```

这个grid和block严格来讲并不是给sort用的，而是生成反向索引，为sort做准备。

```text
C10_LAUNCH_BOUNDS_1(at::cuda::detail::CUDA_NUM_THREADS)
__global__ void fill_reverse_indices_kernel(
    int64_t* data,
    int numel,
    at::cuda::detail::IntDivider<uint32_t> nsort_divider) {
  CUDA_KERNEL_LOOP(idx, numel) {
    data[idx] = nsort_divider.mod(idx);
  }
}
```

其实也就是索引除余，例如(3,4)问题，就得到下面关系，可以理解为全局索引到局部索引

```text
>>> a = torch.randn(3,4)
>>> a.sort()
torch.return_types.sort(
values=tensor([[-0.0118,  0.1820,  0.6307,  1.4404],
        [-0.6229, -0.3086, -0.0204,  0.7746],
        [-0.9992, -0.0216,  0.1215,  0.9571]]),
indices=tensor([[2, 1, 3, 0],
        [0, 3, 1, 2],
        [1, 0, 3, 2]]))



0 1 2 3  ==》 0 1 2 3
4 5 6 7       0 1 2 3
8 9 10 11     0 1 2 3
```

再向下的代码就要调用到at::cuda::cub::segmented\_sort\_pairs了，但是在调用之前，先简单看一下offset\_t是什么，这个提供了偏移计算，对于Begin 就是nsort\*i, 对于end就是nsort\* (i+1), 也就是排序begin-end之间的数，到后面用到。

```text
struct offset_t {
  int stride;
  int begin;
  __device__ int operator[](int i) {
    return stride * (begin + i);
  }
};
```

终于到了at::cuda::cub::segmented\_sort\_pairs本身，从名字已经可以看出与cub有关，但其实还在pytorch源码中，在at::cuda::cub这个命名空间中的代码都是pytorch中负责调用cub的部分，可以看出，参数基本还是那些参数，只是类型在特定场景（主要是半精度的命名）下会变一下

```text
template<typename key_t, typename value_t, typename OffsetIteratorT>
inline void segmented_sort_pairs(
    const key_t *keys_in, key_t *keys_out,
    const value_t *values_in, value_t *values_out,
    int64_t num_elements, int64_t num_segments,
    OffsetIteratorT begin_offsets, OffsetIteratorT end_offsets,
    bool descending=false, int64_t begin_bit=0, int64_t end_bit=sizeof(key_t)*8
) {
  TORCH_CHECK(num_elements <= std::numeric_limits<int>::max(),
    "cub sort does not support sorting more than INT_MAX elements");
  TORCH_CHECK(num_segments <= std::numeric_limits<int>::max(),
    "cub sort does not support sorting more than INT_MAX elements");
  using key_t_ = typename detail::cuda_type<key_t>::type;

  auto allocator = c10::cuda::CUDACachingAllocator::get();
  c10::DataPtr keys_out_owner;

  if (keys_out == nullptr) {
    keys_out_owner = allocator->allocate(num_elements * sizeof(key_t));
    keys_out = reinterpret_cast<key_t *>(keys_out_owner.get());
  }

  const key_t_ *keys_in_ = reinterpret_cast<const key_t_*>(keys_in);
  key_t_ *keys_out_ = reinterpret_cast<key_t_*>(keys_out);

  if (descending) {
    CUB_WRAPPER(NO_ROCM(at_cuda_detail)::cub::DeviceSegmentedRadixSort::SortPairsDescending,
      keys_in_, keys_out_, values_in, values_out,
      num_elements, num_segments, begin_offsets, end_offsets,
      begin_bit, end_bit, c10::cuda::getCurrentCUDAStream());
  } else {
    CUB_WRAPPER(NO_ROCM(at_cuda_detail)::cub::DeviceSegmentedRadixSort::SortPairs,
      keys_in_, keys_out_, values_in, values_out,
      num_elements, num_segments, begin_offsets, end_offsets,
      begin_bit, end_bit, c10::cuda::getCurrentCUDAStream());
  }
}
```

CUB\_WRAPPER是一个启动器，其中cub::DeviceSegmentedRadixSort::SortPairs就是这个func，会两次调用它，第一次先获取需要的辅助空间，并申请这部分空间，第二次才是真正的调用。再下面的代码，就到cub库里面去了。

```text
#define CUB_WRAPPER(func, ...) do {                                       \
  size_t temp_storage_bytes = 0;                                          \
  func(nullptr, temp_storage_bytes, __VA_ARGS__);                         \
  auto& caching_allocator = *::c10::cuda::CUDACachingAllocator::get();    \
  auto temp_storage = caching_allocator.allocate(temp_storage_bytes);     \
  func(temp_storage.get(), temp_storage_bytes, __VA_ARGS__);              \
  AT_CUDA_CHECK(cudaGetLastError());                                      \
} while (false)
```

cub库中的代码有很多工程性痕迹，像下面代码位于cub/device/device\_segmented\_radix\_sort.cuh，搞了个doublebuffer后直接Dispatch了

```text
  template <typename KeyT,
            typename ValueT,
            typename BeginOffsetIteratorT,
            typename EndOffsetIteratorT>
  CUB_RUNTIME_FUNCTION static cudaError_t
  SortPairs(void *d_temp_storage,
            size_t &temp_storage_bytes,
            const KeyT *d_keys_in,
            KeyT *d_keys_out,
            const ValueT *d_values_in,
            ValueT *d_values_out,
            int num_items,
            int num_segments,
            BeginOffsetIteratorT d_begin_offsets,
            EndOffsetIteratorT d_end_offsets,
            int begin_bit       = 0,
            int end_bit         = sizeof(KeyT) * 8,
            cudaStream_t stream = 0)
  {
    // Signed integer type for global offsets
    using OffsetT = int;

    DoubleBuffer<KeyT> d_keys(const_cast<KeyT *>(d_keys_in), d_keys_out);
    DoubleBuffer<ValueT> d_values(const_cast<ValueT *>(d_values_in),
                                  d_values_out);

    return DispatchSegmentedRadixSort<false,
                                      KeyT,
                                      ValueT,
                                      BeginOffsetIteratorT,
                                      EndOffsetIteratorT,
                                      OffsetT>::Dispatch(d_temp_storage,
                                                         temp_storage_bytes,
                                                         d_keys,
                                                         d_values,
                                                         num_items,
                                                         num_segments,
                                                         d_begin_offsets,
                                                         d_end_offsets,
                                                         begin_bit,
                                                         end_bit,
                                                         false,
                                                         stream);
  }
```

在dispatch之前，先看一下double buffer, 这个是在cuda编程中一个很经典的优化，这个DoubleBuffer类并没有太多复杂的逻辑，只是对两个buffer封装了一下，后续用到了再看。

```text
template <typename T>
struct DoubleBuffer
{
  /// Pair of device buffer pointers
  T* d_buffers[2];

  ///  Selector into \p d_buffers (i.e., the active/valid buffer)
  int selector;

  /// \brief Constructor
  _CCCL_HOST_DEVICE _CCCL_FORCEINLINE DoubleBuffer()
  {
    selector     = 0;
    d_buffers[0] = NULL;
    d_buffers[1] = NULL;
  }

  /// \brief Constructor
  _CCCL_HOST_DEVICE _CCCL_FORCEINLINE DoubleBuffer(T* d_current, ///< The currently valid buffer
                                                   T* d_alternate) ///< Alternate storage buffer of the same size as \p
                                                                   ///< d_current
  {
    selector     = 0;
    d_buffers[0] = d_current;
    d_buffers[1] = d_alternate;
  }

  /// \brief Return pointer to the currently valid buffer
  _CCCL_HOST_DEVICE _CCCL_FORCEINLINE T* Current()
  {
    return d_buffers[selector];
  }

  /// \brief Return pointer to the currently invalid buffer
  _CCCL_HOST_DEVICE _CCCL_FORCEINLINE T* Alternate()
  {
    return d_buffers[selector ^ 1];
  }
};
```

下面看DispatchSegmentedRadixSort把代码扔哪去了，其定义在cub/device/dispatch/dispatch\_radix\_sort.cuh，看到cub/device/dispatch还有很多其他的代码，比如scan算法等。

DispatchSegmentedRadixSort 是SelectedPolicy的子类，而SelectedPolicy是DeviceRadixSortPolicy<KeyT, ValueT, OffsetT>，

```text
template <
    bool     IS_DESCENDING,     ///< Whether or not the sorted-order is high-to-low
    typename KeyT,              ///< Key type
    typename ValueT,            ///< Value type
    typename BeginOffsetIteratorT,   ///< Random-access input iterator type for reading segment beginning offsets \iterator
    typename EndOffsetIteratorT,   ///< Random-access input iterator type for reading segment ending offsets \iterator
    typename OffsetT,           ///< Signed integer type for global offsets
    typename SelectedPolicy = DeviceRadixSortPolicy<KeyT, ValueT, OffsetT>,
    typename DecomposerT = detail::identity_decomposer_t>
struct DispatchSegmentedRadixSort : SelectedPolicy
```

那这个Dispatch方法到底干什么？很遗憾我们找到它后，它又定义了一个DispatchSegmentedRadixSort，只不过加上了 ptx\_version，这个构造函数只是将这些参数给到成员变量，然后就没然后了，也就是核心执行，只有MaxPolicyT::Invoke(ptx\_version, dispatch)这一行代码。

```text
    /// Internal dispatch routine
    CUB_RUNTIME_FUNCTION __forceinline__
    static cudaError_t Dispatch(
        void*                   d_temp_storage,         ///< [in] Device-accessible allocation of temporary storage.  When NULL, the required allocation size is written to \p temp_storage_bytes and no work is done.
        size_t                  &temp_storage_bytes,    ///< [in,out] Reference to size in bytes of \p d_temp_storage allocation
        DoubleBuffer<KeyT>      &d_keys,                ///< [in,out] Double-buffer whose current buffer contains the unsorted input keys and, upon return, is updated to point to the sorted output keys
        DoubleBuffer<ValueT>    &d_values,              ///< [in,out] Double-buffer whose current buffer contains the unsorted input values and, upon return, is updated to point to the sorted output values
        int                     num_items,              ///< [in] Number of items to sort
        int                     num_segments,           ///< [in] The number of segments that comprise the sorting data
        BeginOffsetIteratorT    d_begin_offsets,        ///< [in] Random-access input iterator to the sequence of beginning offsets of length \p num_segments, such that <tt>d_begin_offsets[i]</tt> is the first element of the <em>i</em><sup>th</sup> data segment in <tt>d_keys_*</tt> and <tt>d_values_*</tt>
        EndOffsetIteratorT      d_end_offsets,          ///< [in] Random-access input iterator to the sequence of ending offsets of length \p num_segments, such that <tt>d_end_offsets[i]-1</tt> is the last element of the <em>i</em><sup>th</sup> data segment in <tt>d_keys_*</tt> and <tt>d_values_*</tt>.  If <tt>d_end_offsets[i]-1</tt> <= <tt>d_begin_offsets[i]</tt>, the <em>i</em><sup>th</sup> is considered empty.
        int                     begin_bit,              ///< [in] The beginning (least-significant) bit index needed for key comparison
        int                     end_bit,                ///< [in] The past-the-end (most-significant) bit index needed for key comparison
        bool                    is_overwrite_okay,      ///< [in] Whether is okay to overwrite source buffers
        cudaStream_t            stream)                 ///< [in] CUDA stream to launch kernels within.  Default is stream<sub>0</sub>.
    {
        typedef typename DispatchSegmentedRadixSort::MaxPolicy MaxPolicyT;

        cudaError_t error;
        do {
            // Get PTX version
            int ptx_version = 0;
            if (CubDebug(error = PtxVersion(ptx_version))) break;

            // Create dispatch functor
            DispatchSegmentedRadixSort dispatch(
                d_temp_storage, temp_storage_bytes,
                d_keys, d_values,
                num_items, num_segments, d_begin_offsets, d_end_offsets,
                begin_bit, end_bit, is_overwrite_okay,
                stream, ptx_version);

            // Dispatch to chained policy
            if (CubDebug(error = MaxPolicyT::Invoke(ptx_version, dispatch))) break;

        } while (0);

        return error;
    }
```

MaxPolicyT又是啥，是DispatchSegmentedRadixSort::MaxPolicy

还记得说过DispatchSegmentedRadixSort 是SelectedPolicy的子类，SelectedPolicy是DeviceRadixSortPolicy<KeyT, ValueT, OffsetT>不，DeviceRadixSortPolicy就定义了很多根据SM不同运行策略，比如SM90 SM80,根据不同的硬件情况，选择不同的参数。而MaxPolicy对应着Policy900，也就是最先进的SM。

那么光选硬件先进了，不兼容怎么办？注意到所有策略都是ChainedPolicy的子类，

```text
struct Policy900 : ChainedPolicy<900, Policy900, Policy800>
```

也就是所有策略都被链接起来，一个不行就换下一个，直到匹配为止。

```text
template <int PTX_VERSION, typename PolicyT, typename PrevPolicyT>
struct ChainedPolicy
{
  /// The policy for the active compiler pass
  using ActivePolicy =
    cub::detail::conditional_t<(CUB_PTX_ARCH < PTX_VERSION), typename PrevPolicyT::ActivePolicy, PolicyT>;

  /// Specializes and dispatches op in accordance to the first policy in the chain of adequate PTX version
  template <typename FunctorT>
  CUB_RUNTIME_FUNCTION _CCCL_FORCEINLINE static cudaError_t Invoke(int ptx_version, FunctorT& op)
  {
    if (ptx_version < PTX_VERSION)
    {
      return PrevPolicyT::Invoke(ptx_version, op);
    }
    return op.template Invoke<PolicyT>();
  }
};
```

如果匹配上来，就会运行到DispatchSegmentedRadixSort的Invoke，ActivePolicyT就是匹配到的策略，看新不看旧，假设是Policy900，对应SM90，也就是H100等卡。

```text
    template <typename ActivePolicyT>
    CUB_RUNTIME_FUNCTION __forceinline__
    cudaError_t Invoke()
    {
        typedef typename DispatchSegmentedRadixSort::MaxPolicy MaxPolicyT;

        // Return if empty problem, or if no bits to sort and double-buffering is used
        if (num_items == 0 || (begin_bit == end_bit && is_overwrite_okay))
        {
            if (d_temp_storage == nullptr)
            {
                temp_storage_bytes = 1;
            }
            return cudaSuccess;
        }

        // Force kernel code-generation in all compiler passes
        return InvokePasses<ActivePolicyT>(
            DeviceSegmentedRadixSortKernel<MaxPolicyT, false,   IS_DESCENDING, KeyT, ValueT, BeginOffsetIteratorT, EndOffsetIteratorT, OffsetT, DecomposerT>,
            DeviceSegmentedRadixSortKernel<MaxPolicyT, true,    IS_DESCENDING, KeyT, ValueT, BeginOffsetIteratorT, EndOffsetIteratorT, OffsetT, DecomposerT>);
    }
```

下面我们看InvokePasses的第一部分逻辑，对应：也就是获取辅助显存是多大。

```text
CUB_WRAPPER(func, ...) do {                                       \
  size_t temp_storage_bytes = 0;                                          \
  func(nullptr, temp_storage_bytes, __VA_ARGS__);   
```

对于基数排序 其空间复杂度是O(N)，但是由于是key value两对排序，所以空间复杂度是2N。

这是两块内存， AliasTemporaries会尝试合并一下返回一个总值，也就是temp\_storage\_bytes

获取完需要的显存大小后，如果d\_temp\_storage是空，直接返回就好，由pytorch负责分配显存，这样是为了统一管理。

```text
        /// Invocation (run multiple digit passes)
    template <
        typename                ActivePolicyT,          ///< Umbrella policy active for the target device
        typename                SegmentedKernelT>       ///< Function type of cub::DeviceSegmentedRadixSortKernel
    CUB_RUNTIME_FUNCTION __forceinline__
    cudaError_t InvokePasses(
        SegmentedKernelT     segmented_kernel,          ///< [in] Kernel function pointer to parameterization of cub::DeviceSegmentedRadixSortKernel
        SegmentedKernelT     alt_segmented_kernel)      ///< [in] Alternate kernel function pointer to parameterization of cub::DeviceSegmentedRadixSortKernel
    {
        cudaError error = cudaSuccess;
        do
        {
            // Init regular and alternate kernel configurations
            PassConfig<SegmentedKernelT> pass_config, alt_pass_config;
            if ((error = pass_config.template       InitPassConfig<typename ActivePolicyT::SegmentedPolicy>(segmented_kernel))) break;
            if ((error = alt_pass_config.template   InitPassConfig<typename ActivePolicyT::AltSegmentedPolicy>(alt_segmented_kernel))) break;

            // Temporary storage allocation requirements
            void* allocations[2] = {};
            size_t allocation_sizes[2] =
            {
                (is_overwrite_okay) ? 0 : num_items * sizeof(KeyT),                      // bytes needed for 3rd keys buffer
                (is_overwrite_okay || (KEYS_ONLY)) ? 0 : num_items * sizeof(ValueT),     // bytes needed for 3rd values buffer
            };

            // Alias the temporary allocations from the single storage blob (or compute the necessary size of the blob)
            if (CubDebug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes))) break;

            // Return if the caller is simply requesting the size of the storage allocation
            if (d_temp_storage == NULL)
            {
                if (temp_storage_bytes == 0)
                    temp_storage_bytes = 1;
                return cudaSuccess;
            }
```

下面看CUB\_WRAPPER的第二部分，也就是已经有d\_temp\_storage了，后面真正干活的逻辑。

```text
#define CUB_WRAPPER(func, ...) do {                                       \
  size_t temp_storage_bytes = 0;                                          \
  func(nullptr, temp_storage_bytes, __VA_ARGS__);                         \
  auto& caching_allocator = *::c10::cuda::CUDACachingAllocator::get();    \
  auto temp_storage = caching_allocator.allocate(temp_storage_bytes);     \
  func(temp_storage.get(), temp_storage_bytes, __VA_ARGS__);              \
  AT_CUDA_CHECK(cudaGetLastError());                                      \
} while (false)
```

  

之前一直说策略策略，啥是策略，其实主要是grid block和基数排序的bits这些

```text
            // Pass planning.  Run passes of the alternate digit-size configuration until we have an even multiple of our preferred digit size
            int radix_bits          = ActivePolicyT::SegmentedPolicy::RADIX_BITS;
            int alt_radix_bits      = ActivePolicyT::AltSegmentedPolicy::RADIX_BITS;
            int num_bits            = end_bit - begin_bit;
            int num_passes          = CUB_MAX(DivideAndRoundUp(num_bits, radix_bits), 1);
            bool is_num_passes_odd  = num_passes & 1;
            int max_alt_passes      = (num_passes * radix_bits) - num_bits;
            int alt_end_bit         = CUB_MIN(end_bit, begin_bit + (max_alt_passes * alt_radix_bits));
```

以Policy900为例，其SegmentedPolicy是：对于float排序，sizeof大于1，也就是6

num\_bits是32，对于float的32位bit，num\_passes就是6，是偶数。

```text
    struct Policy900 : ChainedPolicy<900, Policy900, Policy800>
    {
        enum {
            PRIMARY_RADIX_BITS     = (sizeof(KeyT) > 1) ? 7 : 5,
            SINGLE_TILE_RADIX_BITS = (sizeof(KeyT) > 1) ? 6 : 5,
            SEGMENTED_RADIX_BITS   = (sizeof(KeyT) > 1) ? 6 : 5,
            ONESWEEP               = true,
            ONESWEEP_RADIX_BITS    = 8,
            OFFSET_64BIT           = sizeof(OffsetT) == 8 ? 1 : 0,
            FLOAT_KEYS             = std::is_same<KeyT, float>::value ? 1 : 0,
        }; 

       using SegmentedPolicy = AgentRadixSortDownsweepPolicy<192,
                                                              39,
                                                              DominantT,
                                                              BLOCK_LOAD_TRANSPOSE,
                                                              LOAD_DEFAULT,
                                                              RADIX_RANK_MEMOIZE,
                                                              BLOCK_SCAN_WARP_SCANS,
                                                              SEGMENTED_RADIX_BITS>;
```

下面是一个double buffer部分，由于is\_overwrite\_okay 和is\_num\_passes\_odd都是false,所以这个就是

d\_keys\_remaining\_passes（allocations\[0\]，d\_keys.Alternate() ）

d\_values\_remaining\_passes（allocations\[1\]，d\_values.Alternate()）

```text
            DoubleBuffer<KeyT> d_keys_remaining_passes(
                (is_overwrite_okay || is_num_passes_odd) ? d_keys.Alternate() : static_cast<KeyT*>(allocations[0]),
                (is_overwrite_okay) ? d_keys.Current() : (is_num_passes_odd) ? static_cast<KeyT*>(allocations[0]) : d_keys.Alternate());

            DoubleBuffer<ValueT> d_values_remaining_passes(
                (is_overwrite_okay || is_num_passes_odd) ? d_values.Alternate() : static_cast<ValueT*>(allocations[1]),
                (is_overwrite_okay) ? d_values.Current() : (is_num_passes_odd) ? static_cast<ValueT*>(allocations[1]) : d_values.Alternate());
```

因为只有一个辅助空间，所以一开始用allocations作为输出，d\_keys作为输入，后面再不停反转使用。

```text
            if (CubDebug(error = InvokePass(
                d_keys.Current(), d_keys_remaining_passes.Current(),
                d_values.Current(), d_values_remaining_passes.Current(),
                current_bit,
                (current_bit < alt_end_bit) ? alt_pass_config : pass_config))) break;

            // Run remaining passes
            while (current_bit < end_bit)
            {
                if (CubDebug(error = InvokePass(
                    d_keys_remaining_passes.d_buffers[d_keys_remaining_passes.selector],    d_keys_remaining_passes.d_buffers[d_keys_remaining_passes.selector ^ 1],
                    d_values_remaining_passes.d_buffers[d_keys_remaining_passes.selector],  d_values_remaining_passes.d_buffers[d_keys_remaining_passes.selector ^ 1],
                    current_bit,
                    (current_bit < alt_end_bit) ? alt_pass_config : pass_config))) break;

                // Invert selectors and update current bit
                d_keys_remaining_passes.selector ^= 1;
                d_values_remaining_passes.selector ^= 1;
            }
```

  

在分析下面代码之前，需要看InitPassConfig 和InvokePass这两个函数，InitPassConfig没啥，就是传参，将policy中的一些值给到passconfig，而InvokePass则是根据这些参数值，真正的执行：

```text
    template <typename PassConfigT>
    CUB_RUNTIME_FUNCTION __forceinline__
    cudaError_t InvokePass(
        const KeyT      *d_keys_in,
        KeyT            *d_keys_out,
        const ValueT    *d_values_in,
        ValueT          *d_values_out,
        int             &current_bit,
        PassConfigT     &pass_config)
    {
        cudaError error = cudaSuccess;
        do
        {
            int pass_bits = CUB_MIN(pass_config.radix_bits, (end_bit - current_bit));

            // Log kernel configuration
            #ifdef CUB_DETAIL_DEBUG_ENABLE_LOG
            _CubLog("Invoking segmented_kernels<<<%lld, %lld, 0, %lld>>>(), "
                    "%lld items per thread, %lld SM occupancy, "
                    "current bit %d, bit_grain %d\n",
                    (long long)num_segments,
                    (long long)pass_config.segmented_config.block_threads,
                    (long long)stream,
                    (long long)pass_config.segmented_config.items_per_thread,
                    (long long)pass_config.segmented_config.sm_occupancy,
                    current_bit,
                    pass_bits);
            #endif

            THRUST_NS_QUALIFIER::cuda_cub::launcher::triple_chevron(
                num_segments, pass_config.segmented_config.block_threads, 0,
                stream
            ).doit(pass_config.segmented_kernel,
                d_keys_in, d_keys_out,
                d_values_in,  d_values_out,
                d_begin_offsets, d_end_offsets, num_segments,
                current_bit, pass_bits, decomposer);

            // Check for failure to launch
            if (CubDebug(error = cudaPeekAtLastError()))
            {
                break;
            }

            // Sync the stream if specified to flush runtime errors
            error = detail::DebugSyncStream(stream);
            if (CubDebug(error))
            {
              break;
            }

            // Update current bit
            current_bit += pass_bits;
        }
        while (0);

        return error;
    }
```

终于看到了doit函数，triple\_chevron就是一个kernel的启动器，启动这个真正的pass\_config.segmented\_kernel，后面是其参数。

至于grid和block就是 num\_segments, pass\_config.segmented\_config.block\_threads 都是根据策略设置，参考RegBoundScaling MemBoundScaling等

```text
struct _CCCL_VISIBILITY_HIDDEN triple_chevron
{
  typedef size_t Size;
  dim3 const grid;
  dim3 const block;
  Size const shared_mem;
  cudaStream_t const stream;

  THRUST_RUNTIME_FUNCTION triple_chevron(dim3 grid_, dim3 block_, Size shared_mem_ = 0, cudaStream_t stream_ = 0)
      : grid(grid_)
      , block(block_)
      , shared_mem(shared_mem_)
      , stream(stream_)
  {}

  template <class K, class... Args>
  cudaError_t _CCCL_HOST doit_host(K k, Args const&... args) const
  {
    k<<<grid, block, shared_mem, stream>>>(args...);
    return cudaPeekAtLastError();
  }
```

DeviceSegmentedRadixSortKernel是真正干活的地方，分为三个部分：

Upsweep Scan Downsweep

Upsweep 统计每个radix桶中的数量，scan根据数量计算前缀和，Downsweep根据前缀和将数据重新排列。

先看共享内存部分，这里使用了union，因为smem资源各个阶段都要用，但是又互不影响。

```text
    __shared__ union
    {
        typename BlockUpsweepT::TempStorage     upsweep;
        typename BlockDownsweepT::TempStorage   downsweep;
        struct
        {
            volatile OffsetT                        reverse_counts_in[RADIX_DIGITS];
            volatile OffsetT                        reverse_counts_out[RADIX_DIGITS];
            typename DigitScanT::TempStorage        scan;
        };

    } temp_storage;

    OffsetT segment_begin   = d_begin_offsets[blockIdx.x];
    OffsetT segment_end     = d_end_offsets[blockIdx.x];
    OffsetT num_items       = segment_end - segment_begin;
```

下面看一下Upsweep部分，发现很简单，就是调用了ProcessRegion方法和ExtractCounts

```text

    OffsetT segment_begin   = d_begin_offsets[blockIdx.x];
    OffsetT segment_end     = d_end_offsets[blockIdx.x];
    OffsetT num_items       = segment_end - segment_begin;

    // Check if empty segment
    if (num_items <= 0)
        return;

    // Upsweep
    BlockUpsweepT upsweep(temp_storage.upsweep, d_keys_in, current_bit, pass_bits, decomposer);
    upsweep.ProcessRegion(segment_begin, segment_end);

    CTA_SYNC();

    // The count of each digit value in this pass (valid in the first RADIX_DIGITS threads)
    OffsetT bin_count[BINS_TRACKED_PER_THREAD];
    upsweep.ExtractCounts(bin_count);

    CTA_SYNC();
```

那么关键的就是这个BlockUpsweepT，他是AgentRadixSortUpsweep，通过policy偏特化实现一些参数。

```text
// Upsweep type
    using BlockUpsweepT =
      AgentRadixSortUpsweep<SegmentedPolicyT, KeyT, OffsetT, DecomposerT>;
```

下面这些参数中，前几个参数比较好理解，关键是后面的

TILE\_ITEMS是每个tile(block)处理的数量总数

BYTES\_PER\_COUNTER是 单个计数器占用的字节数，由于用一个char，所以为1，

PACKING\_RATIO就是4，因为PackedCounter是int，也就是4个字节，一个PackedCounter里面有4个DigitCounter

COUNTER\_LANES就是计数器通道数,打个比方，RADIX\_BITS=6，PACKING\_RATIO=4 LOG\_PACKING\_RATIO=2 LOG\_COUNTER\_LANES = 6-2=4 COUNTER\_LANES=2\*\*4 = 16，也就是需要16个lanes，每个lanes里面，有4个DigitCounter，UNROLL\_COUNT 是用来防止溢出用的。

结合下面smem来看

```text
  // Integer type for digit counters (to be packed into words of PackedCounters)
  typedef unsigned char DigitCounter;

  // Integer type for packing DigitCounters into columns of shared memory banks
  typedef unsigned int PackedCounter;

  static constexpr CacheLoadModifier LOAD_MODIFIER = AgentRadixSortUpsweepPolicy::LOAD_MODIFIER;  


enum
  {
    RADIX_BITS      = AgentRadixSortUpsweepPolicy::RADIX_BITS,
    BLOCK_THREADS   = AgentRadixSortUpsweepPolicy::BLOCK_THREADS,
    KEYS_PER_THREAD = AgentRadixSortUpsweepPolicy::ITEMS_PER_THREAD,

    RADIX_DIGITS = 1 << RADIX_BITS,

    LOG_WARP_THREADS = CUB_PTX_LOG_WARP_THREADS,
    WARP_THREADS     = 1 << LOG_WARP_THREADS,
    WARPS            = (BLOCK_THREADS + WARP_THREADS - 1) / WARP_THREADS,

    TILE_ITEMS = BLOCK_THREADS * KEYS_PER_THREAD,

    BYTES_PER_COUNTER     = sizeof(DigitCounter),
    LOG_BYTES_PER_COUNTER = Log2<BYTES_PER_COUNTER>::VALUE,

    PACKING_RATIO     = sizeof(PackedCounter) / sizeof(DigitCounter),
    LOG_PACKING_RATIO = Log2<PACKING_RATIO>::VALUE,

    LOG_COUNTER_LANES = CUB_MAX(0, int(RADIX_BITS) - int(LOG_PACKING_RATIO)),
    COUNTER_LANES     = 1 << LOG_COUNTER_LANES,

    // To prevent counter overflow, we must periodically unpack and aggregate the
    // digit counters back into registers.  Each counter lane is assigned to a
    // warp for aggregation.

    LANES_PER_WARP = CUB_MAX(1, (COUNTER_LANES + WARPS - 1) / WARPS),

    // Unroll tiles in batches without risk of counter overflow
    UNROLL_COUNT      = CUB_MIN(64, 255 / KEYS_PER_THREAD),
    UNROLLED_ELEMENTS = UNROLL_COUNT * TILE_ITEMS,
  };
```

AgentRadixSortUpsweep有一个最重要的统计数组，也是用union实现的

```text
  /**
   * Shared memory storage layout
   */
  union __align__(16) _TempStorage
  {
    DigitCounter thread_counters[COUNTER_LANES][BLOCK_THREADS][PACKING_RATIO];
    PackedCounter packed_thread_counters[COUNTER_LANES][BLOCK_THREADS];
    OffsetT block_counters[WARP_THREADS][RADIX_DIGITS];
  };
```

其中thread\_counters的主要更新在下面代码：下面代码就比较清晰了，也就是对于每个线程，其都统计全部radix桶的数量，对于2\*\*6就是64种情况。

总共就需要 线程数\*64\* sizeof(int)空间，这个空间是比较大的，共享内存不一定可以装的下。

如果只有64\* sizeof(int)的空间，线程之间就会彼此冲突，性能更差。

那怎么办？就用char(最大255)来统计，一次性最多统计255个数（UNROLL\_COUNT），这样DigitCounter就不会溢出，每次统计完后，再通过UnpackDigitCounts 放到local\_counts中。

其实也就相当于将digit 拆成两半，有高位和低位，分别统计

```text
  /**
   * Decode a key and increment corresponding smem digit counter
   */
  _CCCL_DEVICE _CCCL_FORCEINLINE void Bucket(bit_ordered_type key)
  {
    // Perform transform op
    bit_ordered_type converted_key = bit_ordered_conversion::to_bit_ordered(decomposer, key);

    // Extract current digit bits
    std::uint32_t digit = digit_extractor().Digit(converted_key);

    // Get sub-counter offset
    std::uint32_t sub_counter = digit & (PACKING_RATIO - 1);

    // Get row offset
    std::uint32_t row_offset = digit >> LOG_PACKING_RATIO;

    // Increment counter
    temp_storage.thread_counters[row_offset][threadIdx.x][sub_counter]++;
  }
```

我们分析一下UnpackDigitCounts 函数，之前是每个线程将数据存入共享内存中，现在则是将数据累加到local\_counts，这个是线程私有变量。

之前是每个线程都可能碰见任何值，但是最后的逻辑是尽量让一个线程负责一个radix桶的，cub更极端，先需要通过warp转化一手，进行warp级别的统计。

假设有256个线程，也就是8个warp，因为有16个lane，也就是每个warp负责两个lane

lane是什么？是digit 的高位通道，4bits16种情况，digit的低位是2bits 4种情况，加起来正好是16\*4=64种情况。

一个warp就统计两个lane的4种低位情况。

```text
  // Thread-local counters for periodically aggregating composite-counter lanes
  OffsetT local_counts[LANES_PER_WARP][PACKING_RATIO];
```

对于代码UnpackDigitCounts外层循环就是 0 1，循环的是每个warp负责的lane

warp\_id 是0~7对于8个warp

counter\_lane 则是0~15，对应这16个line

对应线程0，其属于warp0，0和8这两个line属于这个warp

warp\_tid + PACKED\_COUNTER 是0 32 64 96 ... 224 等8个值，参考thread\_counters，也就是这8个线程统计到的值。

对于线程1，其统计的就是1 33 ...225这8个线程统计到的值。

最终就是32个线程，1个warp将256个线程统计到的值（这个值要求高位是LANE,低位是UNPACKED\_COUNTER ），（分成32份）分别存入每个线程的local\_counts

thread\_counters\[0 或 8\]\[0 32 64... 224\]\[0-3\];  
local\_counts\[0-1\]\[0-3\] += counter;

```text
  // Thread-local counters for periodically aggregating composite-counter lanes
  OffsetT local_counts[LANES_PER_WARP][PACKING_RATIO]; 

 _CCCL_DEVICE _CCCL_FORCEINLINE void UnpackDigitCounts()
  {
    unsigned int warp_id  = threadIdx.x >> LOG_WARP_THREADS;
    unsigned int warp_tid = LaneId();

#pragma unroll
    for (int LANE = 0; LANE < LANES_PER_WARP; LANE++)
    {
      const int counter_lane = (LANE * WARPS) + warp_id;
      if (counter_lane < COUNTER_LANES)
      {
#pragma unroll
        for (int PACKED_COUNTER = 0; PACKED_COUNTER < BLOCK_THREADS; PACKED_COUNTER += WARP_THREADS)
        {
#pragma unroll
          for (int UNPACKED_COUNTER = 0; UNPACKED_COUNTER < PACKING_RATIO; UNPACKED_COUNTER++)
          {
            OffsetT counter = temp_storage.thread_counters[counter_lane][warp_tid + PACKED_COUNTER][UNPACKED_COUNTER];
            local_counts[LANE][UNPACKED_COUNTER] += counter;
          }
        }
      }
    }
  }
```

相信大家也已经猜到了，将各个线程拿到其对应统计值后，下面就是需要在reduce一下了，这个操作在ExtractCounts中，BINS\_TRACKED\_PER\_THREAD是每个线程负责多少个radix桶，因为线程数比桶多，所以这里就是1

```text
        /// Number of bin-starting offsets tracked per thread
        BINS_TRACKED_PER_THREAD = CUB_MAX(1, (RADIX_DIGITS + BLOCK_THREADS - 1) / BLOCK_THREADS),
```

对于线程0 warp也是0，LANE属于0，1 counter\_lane就是0 8，digit\_row则是0 32 bin\_idx就是0-3 32-35，这是warp0对应的两个lane对应的8个radix桶。

然而这8个radix桶的数据在这个warp的32个线程之中，所以需要

temp\_storage.block\_counters\[warp\_tid\]\[bin\_idx\] = local\_counts\[LANE\]\[UNPACKED\_COUNTER\]

将其读入共享内存。

其中 block\_counters\[32\]\[64\]，后面的64对应着64个radix桶，32对应着一个warp的32个线程。

最后代码用了一个for循环，累加了一下，bin\_count是一个线程私有值，每个线程对应1个或多个radix桶，这里就是1个，每个线程需要将32个数据累加一下，得到最终结果。

  

```text
    template <int BINS_TRACKED_PER_THREAD>
    __device__ __forceinline__ void ExtractCounts(
        OffsetT (&bin_count)[BINS_TRACKED_PER_THREAD])  ///< [out] The exclusive prefix sum for the digits [(threadIdx.x * BINS_TRACKED_PER_THREAD) ... (threadIdx.x * BINS_TRACKED_PER_THREAD) + BINS_TRACKED_PER_THREAD - 1]
    {
        unsigned int warp_id    = threadIdx.x >> LOG_WARP_THREADS;
        unsigned int warp_tid   = LaneId();

        // Place unpacked digit counters in shared memory
        #pragma unroll
        for (int LANE = 0; LANE < LANES_PER_WARP; LANE++)
        {
            int counter_lane = (LANE * WARPS) + warp_id;
            if (counter_lane < COUNTER_LANES)
            {
                int digit_row = counter_lane << LOG_PACKING_RATIO;

                #pragma unroll
                for (int UNPACKED_COUNTER = 0; UNPACKED_COUNTER < PACKING_RATIO; UNPACKED_COUNTER++)
                {
                    int bin_idx = digit_row + UNPACKED_COUNTER;

                    temp_storage.block_counters[warp_tid][bin_idx] =
                        local_counts[LANE][UNPACKED_COUNTER];
                }
            }
        }

        CTA_SYNC();

        // Rake-reduce bin_count reductions
        #pragma unroll
        for (int track = 0; track < BINS_TRACKED_PER_THREAD; ++track)
        {
            int bin_idx = (threadIdx.x * BINS_TRACKED_PER_THREAD) + track;

            if ((BLOCK_THREADS == RADIX_DIGITS) || (bin_idx < RADIX_DIGITS))
            {
                bin_count[track] = 0;

                #pragma unroll
                for (int i = 0; i < WARP_THREADS; ++i)
                    bin_count[track] += temp_storage.block_counters[i][bin_idx];
            }
        }
    }
```

  

有了上面的基础，看下面代码就简单了，reset是把各种数清零，ProcessFullTile就调用了LoadDirectStriped读取数据和BucketKeys统计值，

```text
  /**
   * Compute radix digit histograms from a segment of input tiles.
   */
  _CCCL_DEVICE _CCCL_FORCEINLINE void ProcessRegion(OffsetT block_offset, const OffsetT& block_end)
  {
    // Reset digit counters in smem and unpacked counters in registers
    ResetDigitCounters();
    ResetUnpackedCounters();

    // Unroll batches of full tiles
    while (block_end - block_offset >= UNROLLED_ELEMENTS)
    {
      for (int i = 0; i < UNROLL_COUNT; ++i)
      {
        ProcessFullTile(block_offset);
        block_offset += TILE_ITEMS;
      }

      CTA_SYNC();

      // Aggregate back into local_count registers to prevent overflow
      UnpackDigitCounts();

      CTA_SYNC();

      // Reset composite counters in lanes
      ResetDigitCounters();
    }

    // Unroll single full tiles
    while (block_end - block_offset >= TILE_ITEMS)
    {
      ProcessFullTile(block_offset);
      block_offset += TILE_ITEMS;
    }

    // Process partial tile if necessary
    ProcessPartialTile(block_offset, block_end);

    CTA_SYNC();

    // Aggregate back into local_count registers
    UnpackDigitCounts();
  }
```

下面代码中去掉了IS\_DESCENDING降序逻辑。统计出各个桶的数量后，就进行计算前缀和了。关于BlockScan有机会单开一篇讲述，这里就知道其是计算前缀和就行。

那么这样的结果是什么呢？比如有64个radix桶，256个线程，最后前64个线程就会记录了64个radix桶的数量，通过bin\_count记录，bin\_offset则是记录了前缀，Exclusive有不包含本身的意思

radix桶(threadIdx.x) 0 1 2 ... 63

记录总数(bin\_count) 10 23 8 ... 7

计算前缀(bin\_offset) 0 10 33 ... 318

计算出这些来后，会发现每个radix桶排列数的起始前缀，就是这个bin\_offset,比如1号radix桶中的数据，要从索引10开始排列，因为前面10个数都是0号radix桶的数据。

```text
    // The count of each digit value in this pass (valid in the first RADIX_DIGITS threads)
    OffsetT bin_count[BINS_TRACKED_PER_THREAD];
    upsweep.ExtractCounts(bin_count);

    CTA_SYNC();


    // Scan
    OffsetT bin_offset[BINS_TRACKED_PER_THREAD];     // The global scatter base offset for each digit value in this pass (valid in the first RADIX_DIGITS threads)
    DigitScanT(temp_storage.scan).ExclusiveSum(bin_count, bin_offset);
```

很遗憾，故事还没有结束，统计完数量后，还需要将值写回，统计数量只是为了知道写回时的一些索引而已。

```text
    // Downsweep
    BlockDownsweepT downsweep(temp_storage.downsweep, bin_offset, num_items, d_keys_in, d_keys_out, d_values_in, d_values_out, current_bit, pass_bits, decomposer);
    downsweep.ProcessRegion(segment_begin, segment_end);
```

BlockDownsweepT 这个玩意是AgentRadixSortDownsweep，和AgentRadixSortUpsweep差不多，但是代码逻辑差很多。

```text
    // Downsweep type
    using BlockDownsweepT = AgentRadixSortDownsweep<SegmentedPolicyT,
                                                    IS_DESCENDING,
                                                    KeyT,
                                                    ValueT,
                                                    OffsetT,
                                                    DecomposerT>;
```

先看构造函数，构造函数中读取了bin\_offset等值，同时有一个小优化，如果所有数据都是一个桶的，在ProcessTile中直接copy就行。

```text
    __device__ __forceinline__ AgentRadixSortDownsweep(
        TempStorage     &temp_storage,
        OffsetT         (&bin_offset)[BINS_TRACKED_PER_THREAD],
        OffsetT         num_items,
        const KeyT      *d_keys_in,
        KeyT            *d_keys_out,
        const ValueT    *d_values_in,
        ValueT          *d_values_out,
        int             current_bit,
        int             num_bits,
        DecomposerT     decomposer = {})
    :
        temp_storage(temp_storage.Alias()),
        d_keys_in(reinterpret_cast<const bit_ordered_type*>(d_keys_in)),
        d_values_in(d_values_in),
        d_keys_out(reinterpret_cast<bit_ordered_type*>(d_keys_out)),
        d_values_out(d_values_out),
        current_bit(current_bit),
        num_bits(num_bits),
        short_circuit(1),
        decomposer(decomposer)
    {
        #pragma unroll
        for (int track = 0; track < BINS_TRACKED_PER_THREAD; ++track)
        {
            this->bin_offset[track] = bin_offset[track];

            int bin_idx = (threadIdx.x * BINS_TRACKED_PER_THREAD) + track;
            if ((BLOCK_THREADS == RADIX_DIGITS) || (bin_idx < RADIX_DIGITS))
            {
                // Short circuit if the histogram has only bin counts of only zeros or problem-size
                short_circuit = short_circuit && ((bin_offset[track] == 0) || (bin_offset[track] == num_items));
            }
        }

        short_circuit = CTA_SYNC_AND(short_circuit);
    }
```

下面看AgentRadixSortDownsweep的 ProcessTile函数看起。由于代码较长，所以先截取部分，一开始主要是读取数据，转化类型。

对于浮点数而言，直接按bit位看也是从小到大，但是首位符号位是反着的，转化类型主要是处理符号位。

读取数据是从显存读取到keys这个显存私有寄存器中。

```text
  /**
   * Process tile
   */
  template <bool FULL_TILE>
  _CCCL_DEVICE _CCCL_FORCEINLINE void ProcessTile(OffsetT block_offset, const OffsetT& valid_items = TILE_ITEMS)
  {
    bit_ordered_type keys[ITEMS_PER_THREAD];
    int ranks[ITEMS_PER_THREAD];
    OffsetT relative_bin_offsets[ITEMS_PER_THREAD];

    // Assign default (min/max) value to all keys
    bit_ordered_type default_key =
      IS_DESCENDING ? traits::min_raw_binary_key(decomposer) : traits::max_raw_binary_key(decomposer);

    // Load tile of keys
    LoadKeys(keys, block_offset, valid_items, default_key, Int2Type<FULL_TILE>(), Int2Type<LOAD_WARP_STRIPED>());

#pragma unroll
    for (int KEY = 0; KEY < ITEMS_PER_THREAD; KEY++)
    {
      keys[KEY] = bit_ordered_conversion::to_bit_ordered(decomposer, keys[KEY]);
    }

 
```

接着就是计算数据的局部排名，别看就3行代码，BlockRadixRank可是非常复杂的类。

```text
    // Rank the twiddled keys
    int exclusive_digit_prefix[BINS_TRACKED_PER_THREAD];
    BlockRadixRankT(temp_storage.radix_rank).RankKeys(keys, ranks, digit_extractor(), exclusive_digit_prefix);

    CTA_SYNC();
```

先看共享内存部分，又是一个union

```text
  union __align__(16) _TempStorage
  {
    typename BlockLoadKeysT::TempStorage load_keys;
    typename BlockLoadValuesT::TempStorage load_values;
    typename BlockRadixRankT::TempStorage radix_rank;

    struct KeysAndOffsets
    {
      bit_ordered_type exchange_keys[TILE_ITEMS];
      OffsetT relative_bin_offsets[RADIX_DIGITS];
    } keys_and_offsets;

    Uninitialized<ValueExchangeT> exchange_values;

    OffsetT exclusive_digit_prefix[RADIX_DIGITS];
  };
```

对于BlockRadixRank，这个共享内存是：是不是和上面很像？PADDED\_COUNTER\_LANES是lane数量+1

RAKING\_SEGMENT = PADDED\_COUNTER\_LANES，剩下都差不多。

```text
  struct __align__(16) _TempStorage
  {
    union Aliasable
    {
      DigitCounter digit_counters[PADDED_COUNTER_LANES][BLOCK_THREADS][PACKING_RATIO];
      PackedCounter raking_grid[BLOCK_THREADS][RAKING_SEGMENT];

    } aliasable;

    // Storage for scanning local ranks
    typename BlockScan::TempStorage block_scan;
  };
```

下面是RankKeys函数，它是个重载，第一层直接调用另一个RankKeys，我们先看三个参数这个。

每个线程一次性都会读取KEYS\_PER\_THREAD个值，存到keys中，然后将这KEYS\_PER\_THREAD个值存到自己线程负责的对应radix桶中，也就是digit\_counters\[counter\_lane\]\[linear\_tid\]\[sub\_counter\]，注意到thread\_prefixes是thread-exclusive而digit\_counters是inclusive，也就是thread\_prefixes是不包含自身的前缀

打个比方，一个线程处理4个值，它们分别属于桶1 桶 2 桶 2 桶 2

在64个radix桶中分别是

0 1 3 0 0 0 0 0 ... 0

那么thread\_prefixes 就是 0 0 1 2

其中后面这个"0 1 2"都是桶2的值，thread\_prefixes就是线程级别的，该往桶2放值的索引。

```text
  template <typename UnsignedBits, int KEYS_PER_THREAD, typename DigitExtractorT>
  _CCCL_DEVICE _CCCL_FORCEINLINE void
  RankKeys(UnsignedBits (&keys)[KEYS_PER_THREAD], int (&ranks)[KEYS_PER_THREAD], DigitExtractorT digit_extractor)
  {
    static_assert(BLOCK_THREADS * KEYS_PER_THREAD <= max_tile_size,
                  "DigitCounter type is too small to hold this number of keys");

    DigitCounter thread_prefixes[KEYS_PER_THREAD]; // For each key, the count of previous keys in this tile having the
                                                   // same digit
    DigitCounter* digit_counters[KEYS_PER_THREAD]; // For each key, the byte-offset of its corresponding digit counter
                                                   // in smem

    // Reset shared memory digit counters
    ResetCounters();

#pragma unroll
    for (int ITEM = 0; ITEM < KEYS_PER_THREAD; ++ITEM)
    {
      // Get digit
      ::cuda::std::uint32_t digit = digit_extractor.Digit(keys[ITEM]);

      // Get sub-counter
      ::cuda::std::uint32_t sub_counter = digit >> LOG_COUNTER_LANES;

      // Get counter lane
      ::cuda::std::uint32_t counter_lane = digit & (COUNTER_LANES - 1);

      if (IS_DESCENDING)
      {
        sub_counter  = PACKING_RATIO - 1 - sub_counter;
        counter_lane = COUNTER_LANES - 1 - counter_lane;
      }

      // Pointer to smem digit counter
      digit_counters[ITEM] = &temp_storage.aliasable.digit_counters[counter_lane][linear_tid][sub_counter];

      // Load thread-exclusive prefix
      thread_prefixes[ITEM] = *digit_counters[ITEM];

      // Store inclusive prefix
      *digit_counters[ITEM] = thread_prefixes[ITEM] + 1;
    }

    CTA_SYNC();

    // Scan shared memory counters
    ScanCounters();

    CTA_SYNC();

// Extract the local ranks of each key
#pragma unroll
    for (int ITEM = 0; ITEM < KEYS_PER_THREAD; ++ITEM)
    {
      // Add in thread block exclusive prefix
      ranks[ITEM] = thread_prefixes[ITEM] + *digit_counters[ITEM];
    }
  }
```

下面的代码逻辑涉及到了ScanCounters，先看Upsweep，Upsweep函数有一个很巧妙的共享内存变化，通过union，用raking\_grid指向了digit\_counters中对应的数据。

digit\_counters是每个线程统计到的每个radix桶的数量，但是注意到raking\_grid和digit\_counters是一个反转，所以raking\_grid是多个线程统计到的某个radix桶的数量。

digit\_counters 完全可以表示为

PackedCounter digit\_counters\[PADDED\_COUNTER\_LANES\]\[BLOCK\_THREADS\]

stride 是 BLOCK\_THREADS ，1

raking\_grid的stride是：

RAKING\_SEGMENT， 1 也就是：

PADDED\_COUNTER\_LANES， 1

raking\_grid的linear\_tid=0对应的值的索引为0~PADDED\_COUNTER\_LANES-1，linear\_tid=1对应的值为PADDED\_COUNTER\_LANES~2\*PADDED\_COUNTER\_LANES-1

digit\_counters对于0号lane, 线程0~PADDED\_COUNTER\_LANES-1，对应的索引为0~PADDED\_COUNTER\_LANES-1，线程PADDED\_COUNTER\_LANES~2\*PADDED\_COUNTER\_LANES-1，对应的索引为PADDED\_COUNTER\_LANES~2\*PADDED\_COUNTER\_LANES-1

```text
      DigitCounter digit_counters[PADDED_COUNTER_LANES][BLOCK_THREADS][PACKING_RATIO];
      PackedCounter raking_grid[BLOCK_THREADS][RAKING_SEGMENT];
```

经过这一次反转后，进行了一次ThreadReduce操作，这个是将多个线程统计的radix桶进行总和

这里面隐含的是值本身不会进位，比如

4 0 2 1四个值用一个int表示，0 1 2 2四个值也用一个int表示，这个int相加，就是4 1 4 3，还是一个int表示

接着往下走，ExclusiveSum中有三个参数，分别为当前线程碰见的值的统计，累加和，以及全部总和，到这里已经有点乱套了 举个例子，radix桶有4个，一个PackedCounter 可以表示两个DigitCounter 也就是有两个lane, 共计用2个PackedCounter表示，PADDED\_COUNTER\_LANES=2+1=3 线程数为4，每个线程处理2个数

```text
线程0在遍历数据的时候，统计到
0 1/ 1 0 
线程1在遍历数据的时候，统计到
2 0 / 0 0
线程2在遍历数据的时候，统计到
0 0 / 0 2
线程3在遍历数据的时候，统计到
1 1 / 0 0
```

  

...

存储到digit\_counters后,布局为

```text
(0 1 ) (2 0)   (0 0)  (1 1）
(1 0 ) (0 0)   (0 2)  (0 0)
(pad空)(pad空)(pad空)(pad空)
```

raking\_grid读取时，对应4个线程，分别为

```text
(0 1 ) (2 0) (0 0 )
(1 1）(1 0 )(0 0)
(0 2)(0 0)(pad空)
(pad空)(pad空)(pad空)
```

进行一次reduce,下面4个值就是Upsweep返回的raking\_partial

```text
(2,1)
(2,1)
(0,2)
(0,0)
```

raking\_partial 不是1个值吗，为什么是2个，因为这是packed。

这里看一下prefix\_call\_back，它会加上对应的高位，

例如(2,1) (2,1) (0,2) (0,0)

block\_aggregate是（4，4）

偏移一下，block\_prefix是（0，4）这边以右边为高位。

原本的前缀为

(0,0) (2,1) (4,2) (4,4)

加上block\_prefix，就是

（0，4）（2，5）（4，6）（4，8）

  

```text
    struct PrefixCallBack
    {
        __device__ __forceinline__ PackedCounter operator()(PackedCounter block_aggregate)
        {
            PackedCounter block_prefix = 0;

            // Propagate totals in packed fields
            #pragma unroll
            for (int PACKED = 1; PACKED < PACKING_RATIO; PACKED++)
            {
                block_prefix += block_aggregate << (sizeof(DigitCounter) * 8 * PACKED);
            }

            return block_prefix;
        }
    };
```

  

再经过ThreadScanExclusive 需要加上对应的前缀（0，4）（2，5）（4，6）（4，8）

```text
(0 1 ) (2 0) (0 0 )
(1 1）(1 0 )(0 0)
(0 2)(0 0)(pad空)
(pad空)(pad空)(pad空)

(0,0) (0,1)(2,1)
(0,0) (1,1)(2,1)
(0,0) (0,2)(0,2)
(0,0) (0,0)(0,0)

(0,4) (0,5)(2,5)
(2,5) (3,6)(4,6)
(4,6) (4,8)(4,8)
(4,8) (4,8)(4,8)
```

  

那么，ExclusiveSum后，

我们把数据横过来看比较明显

```text
原digit_counters
(0,1)(2,0)(0,0)(1,1)  (1,0)(0 0)(0 2)(0,0) (pad空)(pad空)(pad空)(pad空)
现在的digit_counters：
(0,4) (0,5)(2,5)(2,5) (3,6)(4,6)(4,6) (4,8)(4,8)(4,8) (4,8)(4,8)
```

这个意思是每个线程在放置数字时，应当先对一个小桶求前缀，再对另一个小桶求前缀

```text
  _CCCL_DEVICE _CCCL_FORCEINLINE void ExclusiveDownsweep(PackedCounter raking_partial)
  {
    PackedCounter* smem_raking_ptr = temp_storage.aliasable.raking_grid[linear_tid];

    PackedCounter* raking_ptr = (MEMOIZE_OUTER_SCAN) ? cached_segment : smem_raking_ptr;

    // Exclusive raking downsweep scan
    internal::ThreadScanExclusive<RAKING_SEGMENT>(raking_ptr, raking_ptr, Sum(), raking_partial);

    if (MEMOIZE_OUTER_SCAN)
    {
// Copy data back to smem
#pragma unroll
      for (int i = 0; i < RAKING_SEGMENT; i++)
      {
        smem_raking_ptr[i] = cached_segment[i];
      }
    }
  }

 /**
   * Performs upsweep raking reduction, returning the aggregate
   */
  _CCCL_DEVICE _CCCL_FORCEINLINE PackedCounter Upsweep()
  {
    PackedCounter* smem_raking_ptr = temp_storage.aliasable.raking_grid[linear_tid];
    PackedCounter* raking_ptr;

    if (MEMOIZE_OUTER_SCAN)
    {
// Copy data into registers
#pragma unroll
      for (int i = 0; i < RAKING_SEGMENT; i++)
      {
        cached_segment[i] = smem_raking_ptr[i];
      }
      raking_ptr = cached_segment;
    }
    else
    {
      raking_ptr = smem_raking_ptr;
    }

    return internal::ThreadReduce<RAKING_SEGMENT>(raking_ptr, Sum());
  }  

/**
   * Scan shared memory digit counters.
   */
  _CCCL_DEVICE _CCCL_FORCEINLINE void ScanCounters()
  {
    // Upsweep scan
    PackedCounter raking_partial = Upsweep();

    // Compute exclusive sum
    PackedCounter exclusive_partial;
    PrefixCallBack prefix_call_back;
    BlockScan(temp_storage.block_scan).ExclusiveSum(raking_partial, exclusive_partial, prefix_call_back);

    // Downsweep scan with exclusive partial
    ExclusiveDownsweep(exclusive_partial);
  }
```

看完上面扫描后，会发现后面只是将线程前缀加上刚刚算的前缀

计算完成后的digit\_counters，这个相当于全局的前缀和

thread\_prefixes是局部索引，也就是一个线程统计的radix桶里面的数的索引。

两者相加，就是ranks，也就是每个值应当放置的相对位置。

打个比方，线程0统计的两个数，分别在两个radix桶里面，也就是(0 1 )和(1 0 ) ，那么其thread\_prefixes都是0，

两个rank就是4 3

对于线程1，统计的两个值在一个radix桶里面，也就是thread\_prefixes一个为0，一个为1，rank是0 1

对于线程2，rank是6和7

对于线程3，rank是2 5

也就是将这些线程处理的数内部编上号，有了这个编号后，就可以无冲突的将数据放入共享内存exchange\_keys中，exchange\_keys的大小是TILE\_ITEMS，放到这里也就是4\*2=8个值。

```text
原digit_counters
(0,1)(2,0)(0,0)(1,1)
(1,0)(0 0)(0 2)(0,0)
(pad空)(pad空)(pad空)(pad空)
现在的digit_counters：
(0,4) (0,5)(2,5)(2,5) 
(3,6)(4,6)(4,6) (4,8)
(4,8)(4,8) (4,8)(4,8)
```

  

```text
// Extract the local ranks of each key
#pragma unroll
    for (int ITEM = 0; ITEM < KEYS_PER_THREAD; ++ITEM)
    {
      // Add in thread block exclusive prefix
      ranks[ITEM] = thread_prefixes[ITEM] + *digit_counters[ITEM];
    }
  }
```

计算完三个参数的RankKeys，四个参数的RankKeys就是在其基础上，将值赋值给exclusive\_digit\_prefix

注意到，这里只是计算线程0统计到的值，将线程0统计到的radix桶数量放给对应的线程。

比如我们的例子中，4个线程4个radix桶，那么exclusive\_digit\_prefix值分别是0 4 3 6

注意上面counter\_lane 与sub\_counter 的变化，正好让数字从小到大排列了

```text
  template <typename UnsignedBits, int KEYS_PER_THREAD, typename DigitExtractorT>
  _CCCL_DEVICE _CCCL_FORCEINLINE void
  RankKeys(UnsignedBits (&keys)[KEYS_PER_THREAD],
           int (&ranks)[KEYS_PER_THREAD],
           DigitExtractorT digit_extractor,
           int (&exclusive_digit_prefix)[BINS_TRACKED_PER_THREAD])
  {
    static_assert(BLOCK_THREADS * KEYS_PER_THREAD <= max_tile_size,
                  "DigitCounter type is too small to hold this number of keys");

    // Rank keys
    RankKeys(keys, ranks, digit_extractor);

// Get the inclusive and exclusive digit totals corresponding to the calling thread.
#pragma unroll
    for (int track = 0; track < BINS_TRACKED_PER_THREAD; ++track)
    {
      int bin_idx = (linear_tid * BINS_TRACKED_PER_THREAD) + track;

      if ((BLOCK_THREADS == RADIX_DIGITS) || (bin_idx < RADIX_DIGITS))
      {
        if (IS_DESCENDING)
        {
          bin_idx = RADIX_DIGITS - bin_idx - 1;
        }

        // Obtain ex/inclusive digit counts.  (Unfortunately these all reside in the
        // first counter column, resulting in unavoidable bank conflicts.)
        unsigned int counter_lane = (bin_idx & (COUNTER_LANES - 1));
        unsigned int sub_counter  = bin_idx >> (LOG_COUNTER_LANES);

        exclusive_digit_prefix[track] = temp_storage.aliasable.digit_counters[counter_lane][0][sub_counter];
      }
    }
  }
```

我们继续，首先将exclusive\_digit\_prefix读入共享内存，然后计算inclusive\_digit\_prefix 3 4 6 8

bin\_offset是之前统计的radix桶的总值，假设当前是

0 8 16 24,也就是每一个桶里面都是8个值，四个线程对应的bin\_offset值就是0 8 16 24

首先减去对应的0 4 3 6

0 4 13 18，这个就是relative\_bin\_offsets，这个是开始安放数值的坐标，每个线程负责放两个数，之前只是将所有数按照radix桶和线程顺序在exchange\_keys中排列好了，现在线程再重新从其中拿数。

根据digit找到对应的radix桶，然后再用线程偏移得到对应值。

我们用{放数线程id，radix桶id来表示}

exchange\_keys\[{1,0},{1,0},{3,0},{0,2},{0,1}，{3，1}，{2，3}，{2，3}\]

对于线程0，其负责的两个值{1,0} {0,1}在桶0和桶1中，放置坐标为0+0+0=0，4+0+4=8

对于线程1，其负责的两个值{1,0}在桶0，放置坐标为0+1+0=1，{3，1}在桶1，放置坐标为4+1+4=9

对于线程2，其负责的{3,0}值在桶0中，放置坐标为0+2+0=2 另一个{2，3}值在桶3，放置坐标为18+2+4=24

对于线程3，其负责的值{0,2}在桶2中，放置坐标为13+3+0=16 另一个值{2，3}在桶3，放置坐标为18+3+4=25

数据都被放到了合适的地方。

桶0的数据放到了0 1 2

桶1的数据放到了8 9

桶2的数据放到了16

桶3的数据放到了24 25

```text
// Share exclusive digit prefix
#pragma unroll
    for (int track = 0; track < BINS_TRACKED_PER_THREAD; ++track)
    {
      int bin_idx = (threadIdx.x * BINS_TRACKED_PER_THREAD) + track;
      if ((BLOCK_THREADS == RADIX_DIGITS) || (bin_idx < RADIX_DIGITS))
      {
        // Store exclusive prefix
        temp_storage.exclusive_digit_prefix[bin_idx] = exclusive_digit_prefix[track];
      }
    }

    CTA_SYNC();

    // Get inclusive digit prefix
    int inclusive_digit_prefix[BINS_TRACKED_PER_THREAD];

#pragma unroll
    for (int track = 0; track < BINS_TRACKED_PER_THREAD; ++track)
    {
      int bin_idx = (threadIdx.x * BINS_TRACKED_PER_THREAD) + track;
      if ((BLOCK_THREADS == RADIX_DIGITS) || (bin_idx < RADIX_DIGITS))
      {
        if (IS_DESCENDING)
        {
          // Get inclusive digit prefix from exclusive prefix (higher bins come first)
          inclusive_digit_prefix[track] =
            (bin_idx == 0) ? (BLOCK_THREADS * ITEMS_PER_THREAD) : temp_storage.exclusive_digit_prefix[bin_idx - 1];
        }
        else
        {
          // Get inclusive digit prefix from exclusive prefix (lower bins come first)
          inclusive_digit_prefix[track] =
            (bin_idx == RADIX_DIGITS - 1)
              ? (BLOCK_THREADS * ITEMS_PER_THREAD)
              : temp_storage.exclusive_digit_prefix[bin_idx + 1];
        }
      }
    }

    CTA_SYNC();

// Update global scatter base offsets for each digit
#pragma unroll
    for (int track = 0; track < BINS_TRACKED_PER_THREAD; ++track)
    {
      int bin_idx = (threadIdx.x * BINS_TRACKED_PER_THREAD) + track;
      if ((BLOCK_THREADS == RADIX_DIGITS) || (bin_idx < RADIX_DIGITS))
      {
        bin_offset[track] -= exclusive_digit_prefix[track];
        temp_storage.keys_and_offsets.relative_bin_offsets[bin_idx] = bin_offset[track];
        bin_offset[track] += inclusive_digit_prefix[track];
      }
    }
```

  

有了这些坐标索引后，就可以进行最后的填数工作

```text
  /**
   * Scatter ranked keys through shared memory, then to device-accessible memory
   */
  template <bool FULL_TILE>
  _CCCL_DEVICE _CCCL_FORCEINLINE void ScatterKeys(
    bit_ordered_type (&twiddled_keys)[ITEMS_PER_THREAD],
    OffsetT (&relative_bin_offsets)[ITEMS_PER_THREAD],
    int (&ranks)[ITEMS_PER_THREAD],
    OffsetT valid_items)
  {
#pragma unroll
    for (int ITEM = 0; ITEM < ITEMS_PER_THREAD; ++ITEM)
    {
      temp_storage.keys_and_offsets.exchange_keys[ranks[ITEM]] = twiddled_keys[ITEM];
    }

    CTA_SYNC();

#pragma unroll
    for (int ITEM = 0; ITEM < ITEMS_PER_THREAD; ++ITEM)
    {
      bit_ordered_type key       = temp_storage.keys_and_offsets.exchange_keys[threadIdx.x + (ITEM * BLOCK_THREADS)];
      std::uint32_t digit        = digit_extractor().Digit(key);
      relative_bin_offsets[ITEM] = temp_storage.keys_and_offsets.relative_bin_offsets[digit];

      key = bit_ordered_conversion::from_bit_ordered(decomposer, key);

      if (FULL_TILE || (static_cast<OffsetT>(threadIdx.x + (ITEM * BLOCK_THREADS)) < valid_items))
      {
        d_keys_out[relative_bin_offsets[ITEM] + threadIdx.x + (ITEM * BLOCK_THREADS)] = key;
      }
    }
  }
```