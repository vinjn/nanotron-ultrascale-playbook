# pytorch源码分析（1）Tensor

**Author:** 阿嚏

**Date:** 2025-06-19

**Link:** https://zhuanlan.zhihu.com/p/1916807898912257830

Tensor 很多底层实现都是基于其他类的，这里决定从[TensorImpl](https://zhida.zhihu.com/search?content_id=259026992&content_type=Article&match_order=1&q=TensorImpl&zhida_source=entity)讲起，其是intrusive\_ptr\_target的子类，intrusive\_ptr\_target 是一个智能指针的实现，其有一个引用计数，为0时会释放。这里我们就不在深入分析了。

分析TensorImpl 开头，上来就删除了默认构造函数，要求必须通过传参来构造。

又有一个虚析构，确保通过基类指针删除派生类对象时能正确调用完整的析构链

```text
struct C10_API TensorImpl : public c10::intrusive_ptr_target {
  TensorImpl() = delete;
  ~TensorImpl() override;
  // Note [Enum ImplType]
  // This enum is temporary. In the followup refactor we should
  // think about how to specialize TensorImpl creation for view
  // tensors. Currently we only special case its key_set_ but
  // there's also potential to share version_counter_ directly
  // without creating first and then override in as_view.
  enum ImplType { VIEW };

  /**
   * Construct a 1-dim 0-size tensor backed by the given storage.
   */
  TensorImpl(
      Storage&& storage,
      DispatchKeySet,
      const caffe2::TypeMeta data_type);

```

代码在往下，有很多其构造函数，我们主要需要关注TensorImpl的核心成员。

从构造函数也可以看出来，主要有Storage DispatchKeySet const caffe2::TypeMeta 以及std::optional<c10::Device> device\_opt这几个

先看Storage ，和tensor与tensorimpl差不多，storage的核心也是StorageImpl，也是智能指针的一个子类，看其构造函数，核心的有一个数据指针，数据大小，和一个分配器，通过这些信息，我觉得大体可以将Storage看作一个vector

```text
  StorageImpl(
      use_byte_size_t /*use_byte_size*/,
      SymInt size_bytes,
      at::DataPtr data_ptr,
      at::Allocator* allocator,
      bool resizable)
      : data_ptr_(std::move(data_ptr)),
        size_bytes_(std::move(size_bytes)),
        size_bytes_is_heap_allocated_(size_bytes_.is_heap_allocated()),
        resizable_(resizable),
        received_cuda_(false),
        allocator_(allocator) {
    if (resizable) {
      TORCH_INTERNAL_ASSERT(
          allocator_, "For resizable storage, allocator must be provided");
    }
    refresh_has_data_ptr_check();
  }
```

Dispatch机制暂时跳过，后面单开一篇，另一个比较重要的是TypeMeta,device\_opt 也就是数据类型和设备类型。

对于tensor来说，最重要的，除了数据本身的存储（类型，指针，大小，设备），还有shape 和 stride,这里通过SizesAndStrides来存储，之前是两个vector，这里是优化了一下，但也可以理解为就是两个vector而已。

除了这些主要的数据，Tensorimpl还有很多成员，但是我们后续再看。

TensorImpl的上一层是[TensorBase](https://zhida.zhihu.com/search?content_id=259026992&content_type=Article&match_order=1&q=TensorBase&zhida_source=entity), TensorBase和TensorImpl最大不同，就是多了很多所有权的概念，pytorch的设计希望Tensor可以自动释放，就涉及到了很多不同的情况。

```text
class TORCH_API TensorBase {
 public:
  struct unsafe_borrow_t { explicit unsafe_borrow_t() = default; };

 protected:
  // Create a Tensor with a +0 reference count. Special care must be
  // taken to avoid decrementing this reference count at destruction
  // time. Intended to support MaybeOwnedTraits<Tensor>.
  explicit TensorBase(unsafe_borrow_t, const TensorBase& rhs)
      : impl_(c10::intrusive_ptr<at::TensorImpl, UndefinedTensorImpl>::reclaim(rhs.impl_.get())) {}
  friend MaybeOwnedTraits<TensorBase>;

 public:
  TensorBase() = default;
  // This constructor should not be used by end users and is an implementation
  // detail invoked by autogenerated code.
  explicit TensorBase(
      c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl> tensor_impl)
      : impl_(std::move(tensor_impl)) {
    if (impl_.get() == nullptr) {
      throw std::runtime_error("TensorImpl with nullptr is not supported");
    }
  }
  TensorBase(const TensorBase&) = default;
  TensorBase(TensorBase&&) noexcept = default;
```

第一个，借助unsafe\_borrow\_t，不增加Tensor的引用计数

第二个 是一个空的构造函数

第三个 是通过impl直接生成，这是内部使用的

第四个 拷贝构造函数，增加引用计数

第五个 移动构造函数 不增加引用计数

至于其他的，大部分在调用TensorImpl

终于到了最终的Tensor，之所以需要有Tensor和TensorBase，主要是为了编译方便，他们的功能并没有差很多

```text
class TORCH_API Tensor: public TensorBase {
 protected:
  // Create a Tensor with a +0 reference count. Special care must be
  // taken to avoid decrementing this reference count at destruction
  // time. Intended to support MaybeOwnedTraits<Tensor>.
  explicit Tensor(unsafe_borrow_t, const TensorBase& rhs): TensorBase(unsafe_borrow_t{}, rhs) {}
  friend MaybeOwnedTraits<Tensor>;
  friend OptionalTensorRef;
  friend TensorRef;

 public:
  Tensor() = default;
  // This constructor should not be used by end users and is an implementation
  // detail invoked by autogenerated code.
  explicit Tensor(
      c10::intrusive_ptr<TensorImpl, UndefinedTensorImpl> tensor_impl)
      : TensorBase(std::move(tensor_impl)) {}
  Tensor(const Tensor &tensor) = default;
  Tensor(Tensor &&tensor) = default;

  // Implicitly move-constructible from TensorBase, but must be explicit to increase refcount
  explicit Tensor(const TensorBase &base): TensorBase(base) {}
  /*implicit*/ Tensor(TensorBase &&base): TensorBase(std::move(base)) {}
```

同样， explicit Tensor(unsafe\_borrow\_t, const TensorBase& rhs): TensorBase(unsafe\_borrow\_t{}, rhs) {} 不增加引用计数，还有通过impl直接生成的，以及移动和拷贝。

MaybeOwned 是为借用涉及的，可以own这个tensor（移动构造），也可以只是借用一下（只要个指针）因为在很多场景中，不需要非要拥有这个tensor，后面的释放反而麻烦，所以可以选择只是借用一下，不增加引用计数。

  

本文章最初目的是分析pytorch中的gpu\_kernel函数，但是碍于篇幅，本篇文章主要分析其TensorIterator部分。

这个函数主要是处理element-wise问题的，所谓element-wise，就是逐元素操作，例如向量a \[1,2,3,4\]和向量b\[2,2,2,2\]相加得到向量c \[3,4,5,6\]，特点是，将这个任务拆分成\[1,2\]+\[2,2\]和\[3,4\]+\[2,2\]也不会影响最终结果。

这里面涉及到的函数是add，为了方便，也可以将向量称呼为tensor。我们看一下gpu\_kernel的使用示例：

```cpp
// Example:
//
//   auto iter = TensorIteratorConfig()
//     .add_output(output)
//     .add_input(input)
//     .build()
//
// [MyKernel.cpp / MyKernel.cu]
//   cpu_kernel(iter, [](float a, float b) {
//     return a + b;
//   });
//
//   gpu_kernel(iter, []GPU_LAMBDA(float a, float b) -> float {
//     return a + b;
//   });
//
```

首先注意到，有一个iter的概念，其类型为[TensorIteratorBase](https://zhida.zhihu.com/search?content_id=259026992&content_type=Article&match_order=1&q=TensorIteratorBase&zhida_source=entity)，由TensorIteratorConfig构建而来。

为什么会有这个？iter是所有操作数的一个抽象，例如上面的例子有a b 两个输入，有c一个输出，但是也可能有其他情况，例如relu，只有一个输入，一个输出，而TensorIteratorBase将输入输出进行统一管理，并提供了很多方便使用的方法，后面再讲。

gpu\_kernel的第二个参数是一个function，从这里就可以看出，gpu\_kernel的核心逻辑就是在操作数上调用函数，因为是element-wise，将操作数拆分开也不影响结果，gpu\_kernel相当于隐藏了具体的拆分流程，相当于简化了底层cuda编程。

  

在看gpu\_kernel具体实现之前，先看一下TensorIteratorConfig与TensorIteratorBase，在示例中，TensorIteratorConfig添加了一个输出，一个输入，然后就构建了一个TensorIteratorBase。

TensorIteratorConfig 有final被关键字，是不能被继承的，friend表明其可以直接访问TensorIteratorBase的私有成员，可以看出来这两个关系很大。

```text
class TORCH_API TensorIteratorConfig final {
 public:
  friend struct TensorIteratorBase;
  friend struct TensorIterator;

  TensorIteratorConfig() = default;

  C10_DISABLE_COPY_AND_ASSIGN(TensorIteratorConfig);

  /// Construction
  // Stores input/output Tensors without incrementing the reference count.
  // Important: the outputs have to be added before the inputs.
  TensorIteratorConfig& add_output(const TensorBase& output) {
    return add_borrowed_output(output);
  }
  TensorIteratorConfig& add_input(const TensorBase& input) {
    return add_borrowed_input(input);
  }
```

增添输入输出函数并不会增加tensor的引用计数，比较重要的是，必须先加输出。

```text
TensorIteratorConfig& TensorIteratorConfig::add_borrowed_output(const TensorBase& output) {
  TORCH_INTERNAL_ASSERT(
      num_inputs_ == 0,
      "Keep in mind that you have to add all outputs first before adding any input. "
      "For more details, see https://github.com/pytorch/pytorch/wiki/How-to-use-TensorIterator.");
  tensors_.push_back(c10::MaybeOwned<TensorBase>::borrowed(output));
  num_outputs_++;
  return *this;
}

TensorIteratorConfig& TensorIteratorConfig::add_borrowed_input(const TensorBase& input) {
  tensors_.push_back(c10::MaybeOwned<TensorBase>::borrowed(input));
  num_inputs_++;
  return *this;
}
```

MaybeOwned上文也提到了，可以不增加Tensor的引用计数，我们看它是如何做的，首先有两个类型，一个是拥有，一个是借用，其实就是一个是类型本身，一个只是个指针

```text
  using owned_type = T;
  using borrow_type = const T*;
```

然后借用的话，只要个指针，isBorrowed\_=true，否则，通过移动构造，数据所有权转移，isBorrowed\_为false

在这里Tensor作为参数，有个指针能访问其值就可以了，如果非要own，那么原本的Tensor就无法使用了。

```text
  explicit MaybeOwned(const owned_type& t)
      : isBorrowed_(true), borrow_(MaybeOwnedTraits<T>::createBorrow(t)) {}

  /// Don't use this; use owned() instead.
  explicit MaybeOwned(T&& t) noexcept(std::is_nothrow_move_constructible_v<T>)
      : isBorrowed_(false), own_(std::move(t)) {}
 
```

增加输入输出的逻辑很简单，就是向tensors\_这个vector增添数据，并对应增加一下num\_outputs\_ num\_inputs\_，因为有强行要求，先增加输出，再增加输入，所以即便输入输出都在tensors\_中，也是分得清谁是输入谁是输出的。

下面看一下核心成员函数build，因为build涉及很多，所以这里先分析重点内容。

```text
void TensorIteratorBase::build(TensorIteratorConfig& config) {
  // populate some persistent configuration fields
  is_reduction_ = config.is_reduction_;
  enforce_linear_iteration_ = config.enforce_linear_iteration_;

  // fill in operands_ based on configuration
  populate_operands(config);
  // set is_output and is_read_write flags on appropriate tensors
  mark_outputs();
  // Check that the outputs have no internal overlap
  // and do not share memory with inputs.
  compute_mem_overlaps(config);
  // Check that input dimensions are aligned correctly & compute outnames.
  compute_names(config);
  // compute the broadcasted shape
  compute_shape(config);
  // mark outputs for resizing if necessary
  mark_resize_outputs(config);
  // compute the result dtype and device
  compute_types(config);
  // try fast setup output tensor, if failed, fallback to normal setup
  if (!fast_set_up(config)) {
    // compute each tensor's stride after broadcasting
    compute_strides(config);
    // re-order dimensions to improve coalescing
    reorder_dimensions();
    // allocate the output tensor if it's not provided
    allocate_or_resize_outputs();
    // coalesce adjacent dimensions when possible
    if (!is_meta_) coalesce_dimensions();
  }

  if (is_meta_) return;

  auto has_storage = true;
  for (auto& op : operands_) {
    has_storage &= op.tensor_base().has_storage();
  }
  auto privateuse1_without_storage =
     common_device_.type() == DeviceType::PrivateUse1 &&
     !has_storage;

  // XLA and lazy tensors don't have storage, so they don't have an underlying data pointer.
  // Nothing beyond this point is important for meta functions, so it's fine to exit early here.
  // Extend the condition to MAIA tesnors as MAIA tensors also don't have storage.
  if (privateuse1_without_storage  ||
      common_device_.type() == DeviceType::MTIA ||
      common_device_.type() == DeviceType::XLA  ||
      common_device_.type() == DeviceType::IPU  ||
      common_device_.type() == DeviceType::Lazy ||
      common_device_.type() == DeviceType::MAIA  ||
      common_device_.type() == DeviceType::HPU) return;

  for (auto& op : operands_) {
    TORCH_INTERNAL_ASSERT(op.tensor_base().defined());
    if (op.is_const) {
      // NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)
      op.data = const_cast<void*>(op.tensor_base().const_data_ptr());
    } else {
      op.data = op.tensor_base().mutable_data_ptr();
    }
  }

  // zero out offsets
  // If the tensor is a scalar, we leave room for it
  // So index translations in reduction can access
  // a valid value for the offset
  int64_t ndim_offsets = (ndim() ? ndim() : 1);
  view_offsets_ = DimVector(ndim_offsets, 0);
}
```

第一个核心函数是populate\_operands，之前数据一直在tensors中，他们主要是数据类型不同，operandinfo多加了一些信息，比如这个tensor是否为常量，是不是输出之类的。

```text
  SmallVector<c10::MaybeOwned<TensorBase>, 4> tensors_;
  SmallVector<OperandInfo, 4> operands_;

void TensorIteratorBase::populate_operands(TensorIteratorConfig& config) {
  for (const auto idx : c10::irange(config.tensors_.size())) {
    auto& tensor = config.tensors_[idx];
    // If *any* of the arguments is a meta tensor, the overall
    // computation is a meta computation (don't do any work,
    // just compute output information).  This aligns with
    // our multiple dispatch semantics.
    if (tensor->is_meta()) {
      is_meta_ = true;
    }
    operands_.emplace_back(std::move(tensor));
    operands_[idx].is_const = config.is_tensor_const(idx);
  }
  num_outputs_ = config.num_outputs_;
}
```

第二个函数就是标记tensor是否为输出，并且会判断in-place这种特殊情况，也就是输入输出是否是一个tensor。

```text
void TensorIteratorBase::mark_outputs() {
  // TODO: merge this into populate_operands
  //这里遍历的是num_outputs
  for (const auto i : c10::irange(num_outputs_)) {
    operands_[i].is_output = true;
    const auto& output = tensor(i);
    if (!output.defined()) continue;

    // check if output is also an input
    for (const auto arg : c10::irange(num_outputs_, ntensors())) {
      const auto& input = tensor(arg);
      if (output.is_same(input)) {
        operands_[i].is_read_write = true;
      }
    }
  }
}
```

第三个函数有些类似mark\_outputs，不过是判断输入输出是否有重叠

```text
void TensorIteratorBase::compute_mem_overlaps(const TensorIteratorConfig& config) {
  if (!config.check_mem_overlap_) {
    return;
  }
  for (const auto i : c10::irange(num_outputs_)) {
    const auto& output = tensor_base(i);
    if (!output.defined()) continue;
    assert_no_internal_overlap(output);
    for (const auto j : c10::irange(num_outputs_, ntensors())) {
      const auto& input = tensor_base(j);
      if (!input.is_same(output)) {
        assert_no_partial_overlap(output, input);
      }
    }
  }
}
```

compute\_names看着只是起个名字，核心是下面的计算形状，数据类型。

tensor是有广播机制的，tensor A (5,5) tensor B (5,1), 那么A+B会自动变成（5，5）

compute\_shape就是来做这个事情的，可以看出，主要是对input tensor做处理，output tensor 是直接跳过了。

第一个shape直接设置为shape\_，后面则通过infer\_size\_dimvector计算。

```text
void TensorIteratorBase::compute_shape(const TensorIteratorConfig& config) {
  if (config.static_shape_.has_value()) {
    shape_ = *config.static_shape_;
    return;
  }

  all_ops_same_shape_ = true;
  bool has_scalars = false;
  bool has_tensors = false;
  for (auto& op : operands_) {
    if (!op.tensor_base().defined()) continue;

    // For now, don't include output tensors when we're resizing outputs.
    // These shapes don't participate in shape computation.
    // This preserves the legacy behavior where torch.add(..., out=dst) resizes
    // the destination tensor.  If the output tensor is also an input, we'll
    // pick it up later in the operands.
    if (config.resize_outputs_ && op.is_output) continue;
    TORCH_CHECK(!op.tensor_base().unsafeGetTensorImpl()->has_symbolic_sizes_strides(),
      "TensorIterator does not support symbolic shapes; please implement this operator in torch/_refs "
      "using the elementwise or reduction helpers (look at backtrace to find out what operator this is)");
    auto shape = op.tensor_base().sizes();
    if (shape.empty()) {
      has_scalars = true;
    } else {
      has_tensors = true;
    }
    if (has_scalars && has_tensors) {
      all_ops_same_shape_ = false;
    }
    if (shape_.empty()) {
      shape_ = shape;
    } else if (!shape.equals(shape_)) {
      all_ops_same_shape_ = false;
      shape_ = infer_size_dimvector(shape_, shape);
    }
  }
  all_ops_are_scalars_ = !has_tensors;
}
```

我们看一下这个shape的计算,其实就是广播的基本逻辑，对于a b两个shape从后往前看，相等就留下，有一个1，另一个不为1就选不为1的那个

我们看一下首先得到a和b中的最大维度ndim，作为最终的维度（低维向高维看齐）

下面的offset有点不好看，可以将其转化为

ptrdiff\_t dimA = dimsA - 1 - offset = dimsA - 1 -ndim + 1 + i = dimsA - ndim + i

考虑到i是从ndim - 1开始递减，所以值是从dimsA - 1开始递减，也就是tensor a的最后一个维度，tensor b同理。

由于tensor a b不一定有相同的维度，维度不够的就拿1来补

下面有一个检查，要求目前维度，a和b要相等，否则其中有一个维度是1也行，这里就代表着广播。

最后的size就设置为不为1的那个，当然要是都为1，设置成1也行。

举一个例子，tensor a(2,3,4,5) tensor b(4,5) 那么a+b 就是（2，3，4，5），因为 4，5倒着看维度一致，2，3补齐。

如果b是（3，5）那么运行就会报错，因为维度不匹配。

```text
template <typename Container, typename ArrayType>
Container infer_size_impl(ArrayType a, ArrayType b) {
  // Use ptrdiff_t to ensure signed comparison.
  auto dimsA = static_cast<ptrdiff_t>(a.size());
  auto dimsB = static_cast<ptrdiff_t>(b.size());
  auto ndim = dimsA > dimsB ? dimsA : dimsB;
  Container expandedSizes(ndim);

  for (ptrdiff_t i = ndim - 1; i >= 0; --i) {
    ptrdiff_t offset = ndim - 1 - i;
    ptrdiff_t dimA = dimsA - 1 - offset;
    ptrdiff_t dimB = dimsB - 1 - offset;
    auto sizeA = (dimA >= 0) ? a[dimA] : 1;
    auto sizeB = (dimB >= 0) ? b[dimB] : 1;

    TORCH_CHECK(
        sizeA == sizeB || sizeA == 1 || sizeB == 1,
        "The size of tensor a (", sizeA,
        ") must match the size of tensor b (", sizeB,
        ") at non-singleton dimension ", i);

      // 1s map to the other size (even 0).
      expandedSizes[i] = sizeA == 1 ? std::move(sizeB) : std::move(sizeA);
  }

  return expandedSizes;
}
```

mark\_resize\_outputs就是根据上面计算得到的shape\_判断是否要调整output的形状，这里只记一下核心代码：

```text
    if (output.defined() && !output.sizes().equals(shape_)) {
      if (config.resize_outputs_ && !operands_[i].is_read_write) {
        operands_[i].will_resize = true;
        continue;
      }
      // for reduction, output size does not match shape_, as output is reduced size, and shape_ is size of the input
      TORCH_CHECK(is_reduction_,  "output with shape ", output.sizes(), " doesn't match the broadcast shape ",
                 shape_);
    }
```

compute\_types是计算output最终的类型和所在设备。这个函数虽然很长，但个人认为重点并不多，先看设备类型的表示，是一个enum类型，很长，这里就不一一列举了。

```text
enum class DeviceType : int8_t {
  CPU = 0,
  CUDA = 1, // CUDA.
  MKLDNN = 2, // Reserved for explicit MKLDNN
  OPENGL = 3, // OpenGL
  OPENCL = 4, // OpenCL
  IDEEP = 5, // IDEEP.
  HIP = 6, // AMD HIP
```

为了方便使用，这里定义了一些常量

```text
constexpr DeviceType kCPU = DeviceType::CPU;
constexpr DeviceType kCUDA = DeviceType::CUDA;
constexpr DeviceType kHIP = DeviceType::HIP;
```

在函数中，会将第一个不为cpu的设备记录一下：

```text
    // Acquires the first non-CPU device (if any) as the common device
    if (common_device == kCPU && !op.tensor_base().is_cpu()) {
      common_device = op.tensor_base().device();
    }
```

同时，也会根据情况判断一下是否有tensor位于不同的设备，下面这个报错可以说非常经典了，详细算法同学经常会遇到：

```text
    // Checks all tensors are on the same device, if requested
    if (config.check_all_same_device_) {
      // Handles CPU scalars on CUDA kernels that support them
      if (!common_device.is_cpu() &&
          config.allow_cpu_scalars_ && !op.is_output && op.tensor_base().dim() == 0 &&
          op.tensor_base().is_cpu()) {
        TORCH_CHECK(current_cpu_scalars_on_non_cpu < max_cpu_scalars_on_non_cpu,
                    "Trying to pass too many CPU scalars to non-CPU kernel!");
        ++current_cpu_scalars_on_non_cpu;
      } else if (op.device.value() != common_device) {
        TORCH_CHECK(false,
                    "Expected all tensors to be on the same device, but "
                    "found at least two devices, ", common_device, " and ", op.device.value(), "!");
      }
```

ScalarType 数据类型同样是一个枚举类，但是其是通过宏定义写的，看着有些费劲：

```text
enum class ScalarType : int8_t {
#define DEFINE_ST_ENUM_VAL_(_1, n) n,
  AT_FORALL_SCALAR_TYPES_WITH_COMPLEX_AND_QINTS(DEFINE_ST_ENUM_VAL_)
#undef DEFINE_ENUM_ST_ENUM_VAL_
      Undefined,
  NumOptions
};
```

大体枚举的是uint8\_t float之类，目的是给类型一个编号，剩下的基本和device差不多，第一个类型设置为common\_dtype\_，要是不对就报个错，下面的报错大家也很常见：

```text
      TORCH_CHECK(op.target_dtype == common_dtype_,
                  "Found dtype ", op.target_dtype, " but expected ", common_dtype_);
```

有时候对类型要求没有那么严，毕竟类型也是可以转换的，就会到下面的代码中：

```text
  if ((has_different_input_dtypes || all_ops_are_scalars_) && config.promote_inputs_to_common_dtype_) {
    common_dtype_ = compute_common_dtype();
  }
```

后面比较核心的函数compute\_strides，尤其是广播之后，有的tensor的维度扩张了，那么如何通过扩大后的Idx索引到值呢？很简单，将stride设置为0，就是广播了。

我们看一下逻辑，就是如果一个维度之前为1，扩展后不为1，那么这个维度的stride就是0。这样就实现了广播。

```text
void TensorIteratorBase::compute_strides(const TensorIteratorConfig& config) {
  for (auto& op : operands_) {
    if (op.tensor_base().defined() && !op.will_resize) {
      IntArrayRef original_shape = config.static_shape_ ? shape_ : op.tensor_base().sizes();
      auto original_stride = op.tensor_base().strides();
      auto element_size_in_bytes = op.tensor_base().element_size();
      auto offset = ndim() - original_shape.size();
      if (offset > 0)
          op.stride_bytes.resize(ndim(), 0);
      else
          op.stride_bytes.resize(ndim());
      for (const auto i : c10::irange(original_shape.size())) {
        // see NOTE: [Computing output strides]
        if (original_shape[i] == 1 && shape_[offset + i] !=1) {
          op.stride_bytes[offset + i] = 0;
        } else {
          op.stride_bytes[offset + i] = original_stride[i] * element_size_in_bytes;
        }
      }
    }
  }
}
```

再下一个重要的函数是reorder\_dimensions，重新排列维度有助于访问优化，先看其辅助函数permute\_dimensions，功能其实就是tensor 的permute。

```text
void TensorIteratorBase::permute_dimensions(IntArrayRef perm) {
  TORCH_INTERNAL_ASSERT(perm.size() == static_cast<unsigned>(ndim()));

  auto reorder = [perm](IntArrayRef data) {
    auto res = DimVector(data.size(), 0);
    for (const auto i : c10::irange(perm.size())) {
      res[i] = data[perm[i]];
    }
    return res;
  };

  // Update shape and strides
  shape_ = reorder(shape_);
  for (auto& op : operands_) {
    if (!op.stride_bytes.empty()) {
      op.stride_bytes = reorder(op.stride_bytes);
    }
  }
}
```

reorder\_dimensions的函数非常复杂，首先如果enforce\_linear\_iteration\_为false，直接就逆排返回了。

为什么要逆排？Tensor默认是行优先，例如tensor a 的shape是（2，3，4，5），那么它的stride就是(60, 20, 5, 1)，也就是越靠前的维度，它的步长就越大。倒序可以让步长小的在前面，而下面也是这个思路。

```text
void TensorIteratorBase::reorder_dimensions() {
  // Sort the dimensions based on strides in ascending order with reduced dims
  // at the front. NOTE: that this inverts the order of C-contiguous tensors.
  // strides[0] is the fastest moving dimension instead of strides[ndim - 1].
  // See NOTE: [Computing output strides] and inline  comments for more detailed description

  perm_.resize(ndim());
  if (ndim() == 1) {
    perm_[0] = 0;
    return;
  }

  // initialize perm with n-1, n-2, ..., 1, 0
  std::iota(perm_.rbegin(), perm_.rend(), 0);

  // Reordering dimensions changes iteraton order
  if (enforce_linear_iteration_) {
    permute_dimensions(perm_);
    return;
  }
```

下面定义了一个lambda函数，即判断两个维度的顺序，如果为1，dim0应当在dim1后面，如果为-1dim0应该在前面，可以看出来，其核心思路是让步长小的在前面，步长大的在后面。reduce是一种特殊情况，也排到前面。

```text
  // returns 1 if the dim0 should come after dim1, -1 if dim0 should come
  // before dim1, and 0 if the comparison is ambiguous.
  auto should_swap = [&](size_t dim0, size_t dim1) {
    for (const auto arg : c10::irange(ntensors())) {
      // ignore undefined or incorrectly sized tensors
      if (operands_[arg].stride_bytes.empty() || operands_[arg].will_resize) {
        continue;
      }
      int64_t stride0 = operands_[arg].stride_bytes[dim0];
      int64_t stride1 = operands_[arg].stride_bytes[dim1];
      if (is_reduction_ && operands_[arg].is_output) {
        // move reduced dimensions to the front
        // strides of reduced dimensions are always set to 0 by review_reduce_result
        if ((stride0 == 0) != (stride1 == 0)) {
          return stride1 == 0 ? 1 : -1;
        }
      }
      //move on to the next input if one of the dimensions is broadcasted
      if (stride0 == 0 || stride1 == 0) {
        continue;
      // it is important to return here only with strict comparisons, for equal strides we try to break the tie later
      // by comparing corresponding dimensions or if that does not work, moving on to the next tensor
      } else if (stride0 < stride1) {
        return -1;
      } else  if (stride0 > stride1) {
        return 1;
      } else { //equal strides, use dimensions themselves as the tie-breaker.
        //at this point, with zero strides out of the way, we are guaranteed that operand dimensions are equal to shape_
         auto t_dim0 = shape_[dim0];
         auto t_dim1 = shape_[dim1];
         //return only if dimensions should be swapped, otherwise move on to the next tensor
         if (t_dim0 > t_dim1) {
             return 1;
         }
      }
    }
    return 0;
  };
```

在下面就是一个简单的插入排序，归根到底，还是希望步长小的维度放到前面，至于原因，在[pytorch 源码分析（3）gpu\_kernel （2）](https://zhuanlan.zhihu.com/p/1917874917367611994)中有原因。

```text
  // insertion sort with support for ambiguous comparisons
  for (const auto i : c10::irange(1, ndim())) {
    int dim1 = i;
    for (int dim0 = i - 1; dim0 >= 0; dim0--) {
      int comparison = should_swap(perm_[dim0], perm_[dim1]);
      if (comparison > 0) {
        std::swap(perm_[dim0], perm_[dim1]);
        dim1 = dim0;
      } else if (comparison < 0) {
        break;
      }
    }
```

下一个函数是allocate\_or\_resize\_outputs， output tensor可能没有给，所以也可能会申请一下，这一部分暂时跳过。

最后一个重要的函数是coalesce\_dimensions维度合并，减少张量维度，有助于提高后续操作效率。  
首先是一个Lambda函数can\_coalesce ，判断是否可以合并维度，判断标准是shape\[n\] \* stride\[n\] == stride\[n + 1\]

例如tensor a 的shape是（2，3，4，5），它的stride是(1，2，6，24)，那就可以合并，因为1\*2=2 3\*2=6 4\*6=24

那么如果stride是(60, 20, 5, 1)，就合并不了。

```text
void TensorIteratorBase::coalesce_dimensions() {
  if (ndim() <= 1) {
    return;
  }

  // We can coalesce two adjacent dimensions if either dim has size 1 or if:
  // shape[n] * stride[n] == stride[n + 1].
  auto can_coalesce = [&](int dim0, int dim1) {
    auto shape0 = shape_[dim0];
    auto shape1 = shape_[dim1];
    if (shape0 == 1 || shape1 == 1) {
      return true;
    }
    for (const auto i : c10::irange(ntensors())) {
      auto& stride = operands_[i].stride_bytes;
      if (shape0 * stride[dim0] != stride[dim1]) {
        return false;
      }
    }
    return true;
  };
```

具体合并操作如下：我们以shape是（2，3，4，5），stride是(1，2，6，24)为例。

由于can\_coalesce(0,1）为真，因为2\*1 = 2 shape\_\[0\] = 6

can\_coalesce(0,2)也会为真，因为6\*1 = 6 shape\_\[0\] = 24

can\_coalesce(0,3)也会为真 因为24\*1 = 24 shape\_\[0\] = 120

这时候shape\_.resize(prev\_dim + 1); 也就是shape\_只剩下一个维度，就是这个120维，而stride没有变，仍然为1，此时，新的shape\_为（120），新的stride为（1），就这么合并起来了。

  

```text
  // replace each operands stride at dim0 with its stride at dim1
  auto replace_stride = [&](int dim0, int dim1) {
    for (const auto i : c10::irange(ntensors())) {
      auto& stride = operands_[i].stride_bytes;
      stride[dim0] = stride[dim1];
    }
  };

  int prev_dim = 0;
  for (const auto dim : c10::irange(1, ndim())) {
    if (can_coalesce(prev_dim, dim)) {
      if (shape_[prev_dim] == 1) {
        replace_stride(prev_dim, dim);
      }
      shape_[prev_dim] *= shape_[dim];
    } else {
      prev_dim++;
      if (prev_dim != dim) {
        replace_stride(prev_dim, dim);
        shape_[prev_dim] = shape_[dim];
      }
    }
  }

  shape_.resize(prev_dim + 1);
  for (const auto i : c10::irange(ntensors())) {
    operands_[i].stride_bytes.resize(ndim());
  }
  has_coalesced_dimensions_ = true;
}
```

  

下面看着是获取tensor的数据指针，其实也就是tensor中的storage中的数据指针，至此 Tensor这部分内容基本就讲解完了。

```text
  for (auto& op : operands_) {
    TORCH_INTERNAL_ASSERT(op.tensor_base().defined());
    if (op.is_const) {
      // NOLINTNEXTLINE(cppcoreguidelines-pro-type-const-cast)
      op.data = const_cast<void*>(op.tensor_base().const_data_ptr());
    } else {
      op.data = op.tensor_base().mutable_data_ptr();
    }
  }
```